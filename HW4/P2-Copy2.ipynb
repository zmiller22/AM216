{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KaOV8WHFZYQy"
   },
   "source": [
    "## Loading the Inception model from the [Applications of Keras](https://keras.io/applications/) or [Transfer learning with a pretrained ConvNet](https://www.tensorflow.org/tutorials/images/transfer_learning)\n",
    "Keras Applications are deep learning models that are made available alongside pre-trained weights. These models can be used for prediction, feature extraction, and fine-tuning.\n",
    "\n",
    "Weights are downloaded automatically when instantiating a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mt8Ilz-KZYQ6"
   },
   "source": [
    "## (a) The Ising Model – try your show that the square lattice data can be trained perfectly using the embeddings of Inception.\n",
    "\n",
    "Get the embeddings first, then build a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution to (a):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-aabd903b4135>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/am216/lib/python3.7/site-packages/tensorflow_datasets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# needs to happen before anything else, since the imports below will try to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# import tensorflow, too.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_compat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0mtf_compat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_tf_install\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/am216/lib/python3.7/site-packages/tensorflow_datasets/core/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisallow_positional_args\u001b[0m  \u001b[0;31m# pylint:disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_builder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBeamBasedBuilder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_builder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBuilderConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_builder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDatasetBuilder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/am216/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapi_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdataset_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfile_format_adapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/am216/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapi_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_compat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/am216/lib/python3.7/site-packages/tensorflow_datasets/core/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVersion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/am216/lib/python3.7/site-packages/tensorflow_datasets/core/utils/tqdm_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauto\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtqdm_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/am216/lib/python3.7/site-packages/tqdm/auto.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTqdmExperimentalWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mautonotebook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"tqdm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"trange\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/am216/lib/python3.7/site-packages/tqdm/autonotebook.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnotebook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTqdmExperimentalWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mwarnings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/am216/lib/python3.7/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mIPYW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# IPython 4.x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mimport\u001b[0m \u001b[0mipywidgets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mIPY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/am216/lib/python3.7/site-packages/ipywidgets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_version\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mversion_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__protocol_version__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__jupyter_widgets_controls_version__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__jupyter_widgets_base_version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwidgets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtraitlets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdlink\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/am216/lib/python3.7/site-packages/ipywidgets/widgets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwidget_style\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStyle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwidget_templates\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTwoByTwoLayout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAppLayout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGridspecLayout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwidget_upload\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFileUpload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/am216/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/am216/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/am216/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/am216/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/am216/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/am216/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.random import rand\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, vmap\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure \n",
    "#tf.compat.v2.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data and shape it for training\n",
    "with tf.device('/CPU:0'):\n",
    "\n",
    "    N = 250\n",
    "    nx, ny = 32, 32\n",
    "\n",
    "    Xsq = np.ndarray((4*N,nx,ny,1))\n",
    "    ysq = np.ndarray(4*N)\n",
    "\n",
    "    for i in np.arange(N):\n",
    "        Xsq[i + 0*N] = np.loadtxt(\"./square_T1/square_T1/{:03d}\".format(i), delimiter=\",\").reshape(nx,ny,1)\n",
    "        ysq[i + 0*N] = 0\n",
    "        Xsq[i + 1*N] = np.loadtxt(\"./square_T2/square_T2/{:03d}\".format(i), delimiter=\",\").reshape(nx,ny,1)\n",
    "        ysq[i + 1*N] = 1\n",
    "        Xsq[i + 2*N] = np.loadtxt(\"./square_T3/square_T3/{:03d}\".format(i), delimiter=\",\").reshape(nx,ny,1)\n",
    "        ysq[i + 2*N] = 2\n",
    "        Xsq[i + 3*N] = np.loadtxt(\"./square_T4/square_T4/{:03d}\".format(i), delimiter=\",\").reshape(nx,ny,1)\n",
    "        ysq[i + 3*N] = 3\n",
    "    \n",
    "    # create train/test splits\n",
    "    Xsq_train, Xsq_test, ysq_train, ysq_test = train_test_split(Xsq, ysq, test_size=0.2, random_state=0)\n",
    "    \n",
    "    # Reshape the data for input into transfer model\n",
    "    Xsq_train, Xsq_test = np.repeat(Xsq_train, 8, 1), np.repeat(Xsq_test, 8, 1)\n",
    "    Xsq_train, Xsq_test = np.repeat(Xsq_train, 8, 2), np.repeat(Xsq_test, 8, 2)\n",
    "    Xsq_train, Xsq_test = np.repeat(Xsq_train, 3, 3), np.repeat(Xsq_test, 3, 3)\n",
    "    #Xsq_train, Xsq_test = tf.cast(Xsq_train, tf.float32), tf.cast(Xsq_test, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the inception model without last layer and disable training\n",
    "with tf.device('/CPU:0'):\n",
    "    base_model = keras.applications.inception_v3.InceptionV3(include_top=False, \n",
    "                                                            weights='imagenet', \n",
    "                                                            input_shape=Xsq_train[0].shape\n",
    "                                                            )\n",
    "\n",
    "    base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the embedded data and normalize\n",
    "global_avg_layer = keras.layers.GlobalAveragePooling2D()\n",
    "Xsq_train_emb, Xsq_test_emb = global_avg_layer(base_model.predict(Xsq_train)), global_avg_layer(base_model.predict(Xsq_test))\n",
    "Xsq_train_emb, Xsq_test_emb = Xsq_train_emb.numpy()/Xsq_train_emb.numpy().max(), Xsq_test_emb.numpy()/Xsq_test_emb.numpy().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xsq_train_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classify_FNN:\n",
    "    def __init__(self):\n",
    "        model = self\n",
    "    \n",
    "    @staticmethod\n",
    "    def build(num_classes, channels_first=False):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dropout(0.25))\n",
    "        model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def get_layers():\n",
    "        layers = [\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "        ]\n",
    "        return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classify_layers(model_class, train_data, train_lbls, test_data, test_lbls, \n",
    "                          num_classes, input_shape, hyperparams):\n",
    "    x_train = train_data\n",
    "    x_test = test_data\n",
    "    \n",
    "    # Create categorical labels\n",
    "    y_train = keras.utils.to_categorical(train_lbls, num_classes)\n",
    "    y_test = keras.utils.to_categorical(test_lbls, num_classes)\n",
    "    \n",
    "    # Instantiate the model\n",
    "    model = model_class.build(num_classes=num_classes)\n",
    "    \n",
    "    # Set hyperparameters\n",
    "    INIT_LR = FNN_hyperparams[0]# learning rate\n",
    "    EPOCHS = FNN_hyperparams[1] # number of epochs\n",
    "    BS = FNN_hyperparams[2] # batch size\n",
    "    OPT = tf.keras.optimizers.Adagrad(lr=INIT_LR) # optimizing function\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=OPT, metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    H = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=EPOCHS,\n",
    "                  batch_size=BS)\n",
    "    \n",
    "    return H, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams should be a tuple of: INIT_LR, EPOCHS, BS\n",
    "FNN_hyperparams = (0.01, 50, 32)\n",
    "H_sq_FNN, sq_FNN_model = train_classify_layers(classify_FNN, Xsq_train_emb, ysq_train,\n",
    "                                     Xsq_test_emb, ysq_test, 4, 2048, FNN_hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_CnhTWD1ZYQ7"
   },
   "source": [
    "## (b)  [Rayleigh-Bénard Convection](https://en.wikipedia.org/wiki/Rayleigh%E2%80%93B%C3%A9nard_convection)\n",
    "\n",
    "RB convection, in which a flow is heated from below and cooled  from  top,  is  one  of  the  paradigmatic  system  in  fluid  dynamics. When the temperature difference between the two plates (in dimensionless form Rayleigh number Ra) is beyond certain threshold, hot fluid tends to go up and cold fluid tends to go down, thus forming convection cells. What we supply here are the temperature snapshots from four different Ra, i.e., $Ra=10^{14}$ as `class0`,$Ra= 10^{13}$ as `class1`, $Ra= 10^{12}$ as `class2`,and $Ra= 10^{11}$ as `class3`.  The flow you see is highly turbulent; not only there are big convection cells but also lots of small vortices.  The original dataset  is  around  4000*2000.   We  have  already  downsampled  the  data into the zip file `fluid_org.zip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EyHNtp3wZYQ8"
   },
   "source": [
    "### (1) Train the data in `fluid_org.zip` with inception.  Show that these images can be classified  into  different $Ra$ nicely  with  inception.  \n",
    "\n",
    "Take the length 2048 embeddings from the Inception model first. Then visualizing how the embeddings distribute using a two component PCA or two component T-SNE, whichever you prefer. Then use any of the previously learned method to train a classifier using the embeddings as input. **Note that T-SNE normally gives you better separation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.random import rand\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, vmap\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T04:18:40.675119Z",
     "start_time": "2020-02-24T04:18:32.328259Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "skbbAOw8ZYQ9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    imgs = []\n",
    "    lbls = []\n",
    "    for file in os.listdir('./fluid_org/fluid_org/'):\n",
    "        imgs.append(np.array(Image.open('./fluid_org/fluid_org/'+file))/255)\n",
    "        lbls.append(int(file[-5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T04:19:30.816271Z",
     "start_time": "2020-02-24T04:19:26.835782Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "QStrmCBWZYRA"
   },
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    imgs = np.array(imgs)\n",
    "    lbls = np.array(lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(751, 250, 500, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution to (1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    base_model_2 = keras.applications.inception_v3.InceptionV3(include_top=False, \n",
    "                                                            weights='imagenet', \n",
    "                                                            input_shape=imgs[0].shape\n",
    "                                                            )\n",
    "\n",
    "    base_model_2.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_avg_layer = keras.layers.GlobalAveragePooling2D()\n",
    "imgs_emb = global_avg_layer(base_model_2.predict(imgs))\n",
    "imgs_emb = imgs_emb.numpy()/imgs_emb.numpy().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(751, 2048)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_img_emb = tsne.fit_transform(imgs_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    plt.plot(tsne_img_emb.transpose()[0][lbls==i],tsne_img_emb.transpose()[1][lbls==i],'.',markersize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n3Klki-zZYRb"
   },
   "source": [
    "### (2) For advanced use of trainsfer learning from the pre-trained models such as fine-tuning, we need to do the transfer learning in-place, by building a network consists of the Inception and your classifier layers. \n",
    "Freeze the part you take from Inception, train\n",
    "the model and report the accuracy. Then do the fine-tuning. Report\n",
    "how much increase of accuracy you can manage to get. Fine tuning\n",
    "by making the top few layer of the Inception model trainable instead\n",
    "of freezing all the layers. Due to the slowness of training, unleash the\n",
    "layers one by one. Make comments about how the accuracy change. It is\n",
    "highly recommended that you train this on Google Colab with the GPU\n",
    "activated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution to (2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_2(model, train_data, train_lbls, test_data, \n",
    "                test_lbls, num_classes, input_shape, hyperparams):\n",
    "    # Ensure data is shaped properly, assumes channels last set up\n",
    "    x_train = train_data\n",
    "    x_test = test_data.reshape((test_data.shape[0],) + input_shape).astype(\"float32\")\n",
    "    \n",
    "    # Create categorical labels\n",
    "    y_train = keras.utils.to_categorical(train_lbls, num_classes)\n",
    "    y_test = keras.utils.to_categorical(test_lbls, num_classes)\n",
    "    \n",
    "    # Set hyperparameters\n",
    "    INIT_LR = hyperparams[0]# learning rate\n",
    "    EPOCHS = hyperparams[1] # number of epochs\n",
    "    BS = hyperparams[2] # batch size\n",
    "    OPT = tf.keras.optimizers.Adagrad(lr=INIT_LR) # optimizing function\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=OPT, metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    H = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=EPOCHS,\n",
    "                  batch_size=BS)\n",
    "    \n",
    "    return H, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classify_FNN:\n",
    "    def __init__(self):\n",
    "        model = self\n",
    "    \n",
    "    @staticmethod\n",
    "    def build(num_classes, channels_first=False):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dropout(0.25))\n",
    "        model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def get_layers(num_classes):\n",
    "        layers = [\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "        ]\n",
    "        return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the full model\n",
    "with tf.device('/CPU:0'):\n",
    "    layer_list = [base_model_2, global_avg_layer]+classify_FNN.get_layers(4)\n",
    "    model = tf.keras.Sequential(layer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 6, 14, 2048)       21802784  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_95 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 22,069,444\n",
      "Trainable params: 266,596\n",
      "Non-trainable params: 21,802,848\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Look at the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test splits\n",
    "train_imgs, test_imgs, train_lbls, test_lbls = train_test_split(imgs, lbls, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 600 samples, validate on 151 samples\n",
      "Epoch 1/50\n",
      "600/600 [==============================] - 15s 25ms/sample - loss: 0.7923 - accuracy: 0.6967 - val_loss: 1.3530 - val_accuracy: 0.3245\n",
      "Epoch 2/50\n",
      "600/600 [==============================] - 6s 11ms/sample - loss: 0.2541 - accuracy: 0.9333 - val_loss: 1.5245 - val_accuracy: 0.2980\n",
      "Epoch 3/50\n",
      "600/600 [==============================] - 6s 10ms/sample - loss: 0.1466 - accuracy: 0.9783 - val_loss: 1.3264 - val_accuracy: 0.4371\n",
      "Epoch 4/50\n",
      "576/600 [===========================>..] - ETA: 0s - loss: 0.1310 - accuracy: 0.9785"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-169154b6e960>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhyperparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_lbls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_lbls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-b42606fcd501>\u001b[0m in \u001b[0;36mtrain_model_2\u001b[0;34m(model, train_data, train_lbls, test_data, test_lbls, num_classes, input_shape, hyperparams)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     H = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=EPOCHS,\n\u001b[0;32m---> 22\u001b[0;31m                   batch_size=BS)\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/am216/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/am216/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/am216/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/am216/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/am216/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/am216/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/am216/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/am216/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/am216/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/am216/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/am216/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hyperparams = (0.01, 50, 64)\n",
    "H, trained_model = train_model_2(model, train_imgs, train_lbls, test_imgs, test_lbls, 4, (250, 500, 3), hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PuQscq_aZYRk"
   },
   "source": [
    "### (3) Explore the potential of transfer learning on cropped data `fluid-crop`, which are randomly choosen regions of 100*100 pixels from each original 4000*2000 pictures, i.e.,just around 1% of the original picture! \n",
    "You can use either method you use in (1) or (2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution to (3):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hzdh9wTPZYRk"
   },
   "source": [
    "### (4) Build your own classifier for (2) and (3) without using Inception. Compare the performance of your own classifier with the result in (2) and (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution to (4):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_xxmW9iPZYRl"
   },
   "source": [
    "### (5) Continue (3), construct two examples where a different layer's output is used as the embedding. There are over 300 layers in Inception. Pick one at around the 100th layer and one at around 200th layer. The exact layer you pick is based on your preference. Show the following.\n",
    "- (i) The distributions of the embeddings similar to what you've done in (1). Together with the result you get in (1), comment the similarity and difference between what you get using the three embedding layers.\n",
    "- (ii) What is the test accuracy of the three classifiers. What is the test accuracy of the three classifiers? For speeding up the training you can choose to get the embeddings first and put those into a classifier, as you did in (1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution to (5):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
