{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:46:46.494051Z",
     "start_time": "2020-02-24T16:46:45.817790Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import rand\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "import gc\n",
    "from numba import cuda\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:46:46.494051Z",
     "start_time": "2020-02-24T16:46:45.817790Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# This is how the triagle lattice data is generated. You may find it helpful to generate some \n",
    "# of your own data\n",
    "class Ising_tri():\n",
    "    ''' Simulating the Ising model '''  \n",
    "    def __init__(self, size, temp):\n",
    "        self.temp = temp\n",
    "        self.N = int(size)\n",
    "    ## monte carlo moves\n",
    "    \n",
    "    def mcmove(self, config, N, beta):\n",
    "        ''' This is to execute the monte carlo moves using \n",
    "        Metropolis algorithm such that detailed\n",
    "        balance condition is satisified'''\n",
    "        for i in range(N):\n",
    "            for j in range(N):            \n",
    "                    a = np.random.randint(0, N) # select a row\n",
    "                    b = np.random.randint(0, N) # select a column\n",
    "                    s =  config[a, b] # current state at (a, b)\n",
    "                    if a%2:\n",
    "                        nb = config[(a+1)%N,b] +config[(a+1)%N,(b+1)%N] + config[a,(b+1)%N] + \\\n",
    "                        config[(a-1)%N,b] + config[(a-1)%N,(b+1)%N] + config[a,(b-1)%N]\n",
    "                    else:\n",
    "                        nb = config[(a+1)%N,b] +config[(a+1)%N,(b-1)%N] + config[a,(b+1)%N] + \\\n",
    "                        config[(a-1)%N,b] + config[(a-1)%N,(b-1)%N] + config[a,(b-1)%N]\n",
    "                    \n",
    "                    \n",
    "                    cost = 2*s*nb\n",
    "                    if cost < 0:\t\n",
    "                        s *= -1\n",
    "                    elif rand() < np.exp(-cost*beta):\n",
    "                        s *= -1\n",
    "                    config[a, b] = s\n",
    "        return config\n",
    "    \n",
    "    def simulate(self):   \n",
    "        ''' This module simulates the Ising model'''\n",
    "        config = 2*np.random.randint(2, size=(self.N,self.N))-1   \n",
    "        msrmnt = 81\n",
    "        for i in range(msrmnt):\n",
    "            self.mcmove(config, self.N, 1.0/self.temp)\n",
    "        return config\n",
    "\n",
    "class Ising_sq():\n",
    "    ''' Simulating the Ising model '''  \n",
    "    def __init__(self, size, temp):\n",
    "        self.temp = temp\n",
    "        self.N = int(size)\n",
    "    ## monte carlo moves\n",
    "\n",
    "    def mcmove(self, config, N, beta):\n",
    "        ''' This is to execute the monte carlo moves using \n",
    "        Metropolis algorithm such that detailed\n",
    "        balance condition is satisified'''\n",
    "        for i in range(N):\n",
    "            for j in range(N):            \n",
    "                    a = np.random.randint(0, N) # select a row\n",
    "                    b = np.random.randint(0, N) # select a column\n",
    "                    s =  config[a, b] # current state at (a, b)\n",
    "                    # periodic boundary condition imposed\n",
    "                    nb = config[(a+1)%N,b] + config[a,(b+1)%N] + config[(a-1)%N,b] + config[a,(b-1)%N]\n",
    "                    cost = 2*s*nb\n",
    "                    if cost < 0:\n",
    "                        s *= -1\n",
    "                    elif rand() < np.exp(-cost*beta):\n",
    "                        s *= -1\n",
    "                    config[a, b] = s\n",
    "        return config\n",
    "    \n",
    "    def simulate(self):   \n",
    "        ''' This module simulates the Ising model'''\n",
    "        config = 2*np.random.randint(2, size=(self.N,self.N))-1   \n",
    "        times = 100\n",
    "        for i in range(times):\n",
    "            self.mcmove(config, self.N, 1.0/self.temp)\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can import 4-temp data for square and triangular lattices as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T22:30:37.313572Z",
     "start_time": "2020-02-20T22:30:34.531268Z"
    }
   },
   "outputs": [],
   "source": [
    "N = 250\n",
    "nx, ny = 32, 32\n",
    "\n",
    "Xsq = np.ndarray((4*N,nx,ny,1))\n",
    "ysq = np.ndarray(4*N)\n",
    "\n",
    "for i in np.arange(N):\n",
    "    Xsq[i + 0*N] = np.loadtxt(\"./square_T1/square_T1/{:03d}\".format(i), delimiter=\",\").reshape(nx,ny,1)\n",
    "    ysq[i + 0*N] = 0\n",
    "    Xsq[i + 1*N] = np.loadtxt(\"./square_T2/square_T2/{:03d}\".format(i), delimiter=\",\").reshape(nx,ny,1)\n",
    "    ysq[i + 1*N] = 1\n",
    "    Xsq[i + 2*N] = np.loadtxt(\"./square_T3/square_T3/{:03d}\".format(i), delimiter=\",\").reshape(nx,ny,1)\n",
    "    ysq[i + 2*N] = 2\n",
    "    Xsq[i + 3*N] = np.loadtxt(\"./square_T4/square_T4/{:03d}\".format(i), delimiter=\",\").reshape(nx,ny,1)\n",
    "    ysq[i + 3*N] = 3\n",
    "\n",
    "Xsq_train, Xsq_test, ysq_train, ysq_test = train_test_split(Xsq, ysq, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T22:31:02.786262Z",
     "start_time": "2020-02-20T22:31:00.698414Z"
    }
   },
   "outputs": [],
   "source": [
    "N = 250\n",
    "nx, ny = 32, 32\n",
    "\n",
    "Xtri = np.ndarray((4*N,nx,ny,1))\n",
    "ytri = np.ndarray(4*N)\n",
    "\n",
    "for i in np.arange(N):\n",
    "    Xtri[i + 0*N] = np.loadtxt(\"./triangle_T1/triangle_T1/{:03d}\".format(i), delimiter=\",\").reshape(nx,ny,1)\n",
    "    ytri[i + 0*N] = 0\n",
    "    Xtri[i + 1*N] = np.loadtxt(\"./triangle_T2/triangle_T2/{:03d}\".format(i), delimiter=\",\").reshape(nx,ny,1)\n",
    "    ytri[i + 1*N] = 1\n",
    "    Xtri[i + 2*N] = np.loadtxt(\"./triangle_T3/triangle_T3/{:03d}\".format(i), delimiter=\",\").reshape(nx,ny,1)\n",
    "    ytri[i + 2*N] = 2\n",
    "    Xtri[i + 3*N] = np.loadtxt(\"./triangle_T4/triangle_T4/{:03d}\".format(i), delimiter=\",\").reshape(nx,ny,1)\n",
    "    ytri[i + 3*N] = 3\n",
    "\n",
    "Xtri_train, Xtri_test, ytri_train, ytri_test = train_test_split(Xtri, ytri, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you know the shape of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T22:31:05.870456Z",
     "start_time": "2020-02-20T22:31:05.864585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data:\n",
      "(800, 32, 32, 1) (800, 32, 32, 1)\n",
      "(800,) (800,)\n",
      "Shape of test data:\n",
      "(200, 32, 32, 1) (200, 32, 32, 1)\n",
      "(200,) (200,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of training data:\")\n",
    "print(Xsq_train.shape, Xtri_train.shape)\n",
    "print(ysq_train.shape, ytri_train.shape)\n",
    "print(\"Shape of test data:\")\n",
    "print(Xsq_test.shape, Xtri_test.shape)\n",
    "print(ysq_test.shape, ytri_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Train a fully connected neural network to do the classification on both datasets. Then, train  a  convolutional  neural  network  to  do  the  classification,  on  both datasets.   Make  a  table  of  your  performance  numbers  for  both  models  and  upload  these  numbers.   This,  together  with  your code,  should be uploaded to the course website when you turn in your homework.\n",
    "\n",
    "The temperatures for square lattice are $T = 1.5, 2.1, 2.4, 3.5$. $T = 2.5, 3.2, 3.8, 5$ for triangle lattice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution to (a):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class small_FNN:\n",
    "    def __init__(self):\n",
    "        model = self\n",
    "    \n",
    "    @staticmethod\n",
    "    def build(width, height, depth, num_classes, channels_first=False):\n",
    "        model = Sequential()\n",
    "\n",
    "        if channels_first == False:\n",
    "            inputShape = (height, width, depth)\n",
    "            chanDim = -1\n",
    "        elif channels_first == True:\n",
    "            inputShape = (depth, height, width)\n",
    "            chanDim = 1\n",
    "            \n",
    "        model.add(Flatten())\n",
    "        \n",
    "        model.add(Dense(256,  activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Dense(128,  activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Dense(16, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(input_model, train_data, train_lbls, test_data, \n",
    "                test_lbls, num_classes, input_shape, hyperparams):\n",
    "    # Ensure data is shaped properly, assumes channels last set up\n",
    "    x_train = train_data\n",
    "    x_test = test_data\n",
    "    \n",
    "    # Create categorical labels\n",
    "    y_train = keras.utils.to_categorical(train_lbls, num_classes)\n",
    "    y_test = keras.utils.to_categorical(test_lbls, num_classes)\n",
    "     \n",
    "    # Set hyperparameters\n",
    "    INIT_LR = hyperparams[0]# learning rate\n",
    "    EPOCHS = hyperparams[1] # number of epochs\n",
    "    BS = hyperparams[2] # batch size\n",
    "    OPT = optimizers.Adagrad(lr=INIT_LR) # optimizing function\n",
    "    \n",
    "    model = input_model\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=OPT, metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    H = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=EPOCHS,\n",
    "                  batch_size=BS)\n",
    "    \n",
    "    return H, model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 1s 1ms/sample - loss: 1.7569 - accuracy: 0.2463 - val_loss: 1.4259 - val_accuracy: 0.2350\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 1.4908 - accuracy: 0.3200 - val_loss: 1.3649 - val_accuracy: 0.2900\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 1.4420 - accuracy: 0.3562 - val_loss: 1.3567 - val_accuracy: 0.3000\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.2978 - accuracy: 0.4238 - val_loss: 1.3165 - val_accuracy: 0.3600\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 1.2472 - accuracy: 0.4363 - val_loss: 1.2665 - val_accuracy: 0.4150\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 106us/sample - loss: 1.2032 - accuracy: 0.4588 - val_loss: 1.2442 - val_accuracy: 0.4200\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 1.1327 - accuracy: 0.4950 - val_loss: 1.1951 - val_accuracy: 0.4400\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 104us/sample - loss: 1.1519 - accuracy: 0.4850 - val_loss: 1.1572 - val_accuracy: 0.4800\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 1.1503 - accuracy: 0.4812 - val_loss: 1.1238 - val_accuracy: 0.5000\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 1.0993 - accuracy: 0.5100 - val_loss: 1.0916 - val_accuracy: 0.5250\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 114us/sample - loss: 1.0720 - accuracy: 0.5312 - val_loss: 1.0763 - val_accuracy: 0.5250\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 109us/sample - loss: 1.0391 - accuracy: 0.5375 - val_loss: 1.0470 - val_accuracy: 0.5300\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 0.9731 - accuracy: 0.5863 - val_loss: 1.0266 - val_accuracy: 0.5350\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 0.9803 - accuracy: 0.5688 - val_loss: 1.0150 - val_accuracy: 0.5400\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 109us/sample - loss: 0.9796 - accuracy: 0.5788 - val_loss: 1.0174 - val_accuracy: 0.5550\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 104us/sample - loss: 0.9622 - accuracy: 0.5800 - val_loss: 1.0002 - val_accuracy: 0.5550\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 0.9050 - accuracy: 0.6112 - val_loss: 0.9806 - val_accuracy: 0.5550\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 0.9082 - accuracy: 0.6062 - val_loss: 0.9646 - val_accuracy: 0.5550\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 114us/sample - loss: 0.9271 - accuracy: 0.6087 - val_loss: 0.9544 - val_accuracy: 0.5550\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.8774 - accuracy: 0.6212 - val_loss: 0.9487 - val_accuracy: 0.5500\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 104us/sample - loss: 0.8604 - accuracy: 0.6350 - val_loss: 0.9384 - val_accuracy: 0.5750\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 0.8353 - accuracy: 0.6388 - val_loss: 0.9259 - val_accuracy: 0.5450\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 106us/sample - loss: 0.8348 - accuracy: 0.6737 - val_loss: 0.9122 - val_accuracy: 0.5600\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.8070 - accuracy: 0.6550 - val_loss: 0.9118 - val_accuracy: 0.5600\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.7860 - accuracy: 0.6712 - val_loss: 0.9009 - val_accuracy: 0.5700\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 104us/sample - loss: 0.7781 - accuracy: 0.6775 - val_loss: 0.8983 - val_accuracy: 0.5750\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 0.7853 - accuracy: 0.6612 - val_loss: 0.8888 - val_accuracy: 0.5850\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 109us/sample - loss: 0.7573 - accuracy: 0.6787 - val_loss: 0.8962 - val_accuracy: 0.5550\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 0.7573 - accuracy: 0.6712 - val_loss: 0.8925 - val_accuracy: 0.5600\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.7276 - accuracy: 0.7000 - val_loss: 0.8930 - val_accuracy: 0.5650\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 104us/sample - loss: 0.7253 - accuracy: 0.6913 - val_loss: 0.8904 - val_accuracy: 0.5800\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 106us/sample - loss: 0.7219 - accuracy: 0.6913 - val_loss: 0.8932 - val_accuracy: 0.5600\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.7057 - accuracy: 0.6875 - val_loss: 0.8966 - val_accuracy: 0.5600\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 107us/sample - loss: 0.6583 - accuracy: 0.7475 - val_loss: 0.8940 - val_accuracy: 0.5650\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 106us/sample - loss: 0.7127 - accuracy: 0.6888 - val_loss: 0.8849 - val_accuracy: 0.5600\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 107us/sample - loss: 0.6659 - accuracy: 0.7025 - val_loss: 0.8891 - val_accuracy: 0.5750\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.6337 - accuracy: 0.7325 - val_loss: 0.8847 - val_accuracy: 0.5550\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 0.6558 - accuracy: 0.7312 - val_loss: 0.9024 - val_accuracy: 0.5650\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 0.6387 - accuracy: 0.7412 - val_loss: 0.9112 - val_accuracy: 0.5500\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.6186 - accuracy: 0.7462 - val_loss: 0.9109 - val_accuracy: 0.5600\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 116us/sample - loss: 0.6163 - accuracy: 0.7412 - val_loss: 0.9166 - val_accuracy: 0.5600\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 115us/sample - loss: 0.6137 - accuracy: 0.7425 - val_loss: 0.9318 - val_accuracy: 0.5300\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 115us/sample - loss: 0.5956 - accuracy: 0.7425 - val_loss: 0.9295 - val_accuracy: 0.5400\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 112us/sample - loss: 0.5861 - accuracy: 0.7462 - val_loss: 0.9242 - val_accuracy: 0.5350\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 114us/sample - loss: 0.6035 - accuracy: 0.7487 - val_loss: 0.9344 - val_accuracy: 0.5500\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 115us/sample - loss: 0.5650 - accuracy: 0.7763 - val_loss: 0.9284 - val_accuracy: 0.5450\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 112us/sample - loss: 0.5805 - accuracy: 0.7663 - val_loss: 0.9172 - val_accuracy: 0.5600\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 0.5693 - accuracy: 0.7575 - val_loss: 0.9150 - val_accuracy: 0.5650\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 0.5664 - accuracy: 0.7625 - val_loss: 0.9049 - val_accuracy: 0.5650\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 0.5390 - accuracy: 0.7525 - val_loss: 0.9051 - val_accuracy: 0.5650\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 1s 1ms/sample - loss: 1.8613 - accuracy: 0.2537 - val_loss: 1.3886 - val_accuracy: 0.2900\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 1.6515 - accuracy: 0.2950 - val_loss: 1.4144 - val_accuracy: 0.2450\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 1.5381 - accuracy: 0.3200 - val_loss: 1.4045 - val_accuracy: 0.2300\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 1.4166 - accuracy: 0.3800 - val_loss: 1.4318 - val_accuracy: 0.2750\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 1.3636 - accuracy: 0.3688 - val_loss: 1.4015 - val_accuracy: 0.2650\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 102us/sample - loss: 1.3201 - accuracy: 0.4200 - val_loss: 1.3674 - val_accuracy: 0.2650\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 1.3033 - accuracy: 0.4162 - val_loss: 1.3276 - val_accuracy: 0.3100\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 1.2170 - accuracy: 0.4512 - val_loss: 1.2915 - val_accuracy: 0.3300\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 1.1948 - accuracy: 0.4825 - val_loss: 1.2557 - val_accuracy: 0.3400\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 1.1633 - accuracy: 0.4613 - val_loss: 1.2197 - val_accuracy: 0.3800\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 1.1086 - accuracy: 0.5113 - val_loss: 1.1944 - val_accuracy: 0.4000\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 1.0975 - accuracy: 0.5163 - val_loss: 1.1639 - val_accuracy: 0.3950\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 1.0663 - accuracy: 0.5238 - val_loss: 1.1353 - val_accuracy: 0.4150\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 1.0182 - accuracy: 0.5475 - val_loss: 1.1080 - val_accuracy: 0.4350\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.9925 - accuracy: 0.5713 - val_loss: 1.1016 - val_accuracy: 0.4550\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 104us/sample - loss: 0.9882 - accuracy: 0.5625 - val_loss: 1.0930 - val_accuracy: 0.4550\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 0.9436 - accuracy: 0.5975 - val_loss: 1.0824 - val_accuracy: 0.4550\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 0.9268 - accuracy: 0.6000 - val_loss: 1.0707 - val_accuracy: 0.4600\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 0.8995 - accuracy: 0.6162 - val_loss: 1.0614 - val_accuracy: 0.4700\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 104us/sample - loss: 0.8321 - accuracy: 0.6550 - val_loss: 1.0659 - val_accuracy: 0.4650\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 0.8742 - accuracy: 0.6087 - val_loss: 1.0621 - val_accuracy: 0.4300\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 104us/sample - loss: 0.8345 - accuracy: 0.6325 - val_loss: 1.0577 - val_accuracy: 0.4500\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 106us/sample - loss: 0.8265 - accuracy: 0.6375 - val_loss: 1.0569 - val_accuracy: 0.4650\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 0.8149 - accuracy: 0.6313 - val_loss: 1.0596 - val_accuracy: 0.4450\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 0.8166 - accuracy: 0.6475 - val_loss: 1.0590 - val_accuracy: 0.4500\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 118us/sample - loss: 0.7857 - accuracy: 0.6737 - val_loss: 1.0449 - val_accuracy: 0.4450\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 107us/sample - loss: 0.7501 - accuracy: 0.6650 - val_loss: 1.0398 - val_accuracy: 0.4450\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 0.7604 - accuracy: 0.6775 - val_loss: 1.0580 - val_accuracy: 0.4150\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.7522 - accuracy: 0.6700 - val_loss: 1.0467 - val_accuracy: 0.4450\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 0.7206 - accuracy: 0.6675 - val_loss: 1.0431 - val_accuracy: 0.4450\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 0.7181 - accuracy: 0.6750 - val_loss: 1.0418 - val_accuracy: 0.4450\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 0.6847 - accuracy: 0.7025 - val_loss: 1.0310 - val_accuracy: 0.4350\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 117us/sample - loss: 0.6736 - accuracy: 0.7113 - val_loss: 1.0209 - val_accuracy: 0.4450\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 112us/sample - loss: 0.6411 - accuracy: 0.7188 - val_loss: 1.0268 - val_accuracy: 0.4350\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 104us/sample - loss: 0.6546 - accuracy: 0.7150 - val_loss: 1.0258 - val_accuracy: 0.4250\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 0.6747 - accuracy: 0.7063 - val_loss: 1.0319 - val_accuracy: 0.4200\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.6542 - accuracy: 0.7025 - val_loss: 1.0162 - val_accuracy: 0.4650\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 0.6085 - accuracy: 0.7262 - val_loss: 1.0197 - val_accuracy: 0.4600\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 107us/sample - loss: 0.6281 - accuracy: 0.7387 - val_loss: 1.0217 - val_accuracy: 0.4550\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 106us/sample - loss: 0.5860 - accuracy: 0.7462 - val_loss: 1.0195 - val_accuracy: 0.4600\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.5566 - accuracy: 0.7613 - val_loss: 1.0201 - val_accuracy: 0.4650\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 104us/sample - loss: 0.6125 - accuracy: 0.7175 - val_loss: 1.0032 - val_accuracy: 0.4700\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 109us/sample - loss: 0.5782 - accuracy: 0.7513 - val_loss: 1.0087 - val_accuracy: 0.4750\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 118us/sample - loss: 0.5634 - accuracy: 0.7663 - val_loss: 1.0007 - val_accuracy: 0.4850\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 106us/sample - loss: 0.6033 - accuracy: 0.7412 - val_loss: 1.0077 - val_accuracy: 0.4900\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 0.5537 - accuracy: 0.7725 - val_loss: 1.0068 - val_accuracy: 0.5000\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.5598 - accuracy: 0.7663 - val_loss: 1.0195 - val_accuracy: 0.5050\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 106us/sample - loss: 0.5516 - accuracy: 0.7575 - val_loss: 1.0161 - val_accuracy: 0.4900\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.5660 - accuracy: 0.7475 - val_loss: 1.0223 - val_accuracy: 0.5150\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 0.5474 - accuracy: 0.7588 - val_loss: 1.0061 - val_accuracy: 0.5250\n"
     ]
    }
   ],
   "source": [
    "input_shape = (32, 32, 1)\n",
    "num_classes = 4\n",
    "fnn_model_sq = small_FNN.build(width=input_shape[0], height=input_shape[1], depth=input_shape[2],\n",
    "                   num_classes=num_classes)\n",
    "fnn_model_tri = small_FNN.build(width=input_shape[0], height=input_shape[1], depth=input_shape[2],\n",
    "                   num_classes=num_classes)\n",
    "\n",
    "# hyperparams should be a tuple of: INIT_LR, EPOCHS, BS\n",
    "FNN_hyperparams = (0.01, 50, 32)\n",
    "H_sq_FNN, sq_FNN_model = train_model(fnn_model_sq, Xsq_train, ysq_train, Xsq_test, ysq_test, num_classes, input_shape, FNN_hyperparams)\n",
    "H_tri_FNN, tri_FNN_model = train_model(fnn_model_tri, Xtri_train, ytri_train, Xtri_test, ytri_test, num_classes, input_shape, FNN_hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Train a convolutional neural network to do the classification, on both datasets. Make a table of your performance numbers for (a) and (b). \n",
    "Try to optimize the performance of your models and compare the result.\n",
    "\n",
    "solution to (b):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN:\n",
    "    def __init__(self):\n",
    "        model = self\n",
    "    \n",
    "    @staticmethod\n",
    "    def build(width, height, depth, num_classes, channels_first=False):\n",
    "        # initialize the model along with the input shape to be\n",
    "        # \"channels last\" and the channels dimension itself\n",
    "        model = Sequential()\n",
    "        \n",
    "        if channels_first == False:\n",
    "            inputShape = (height, width, depth)\n",
    "            chanDim = -1\n",
    "        elif channels_first == True:\n",
    "            inputShape = (depth, height, width)\n",
    "            chanDim = 1\n",
    "            \n",
    "        model.add(Conv2D(32, (5, 5), activation='relu', input_shape=inputShape))\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(Dropout(0.25))\n",
    "                  \n",
    "        model.add(Flatten())\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "        # return the constructed network architecture\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 1s 2ms/sample - loss: 1.3636 - accuracy: 0.2763 - val_loss: 1.2995 - val_accuracy: 0.2600\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 76us/sample - loss: 1.2683 - accuracy: 0.3850 - val_loss: 1.1509 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 76us/sample - loss: 1.0575 - accuracy: 0.5412 - val_loss: 0.8781 - val_accuracy: 0.6300\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 0.9009 - accuracy: 0.5900 - val_loss: 0.8027 - val_accuracy: 0.6000\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 83us/sample - loss: 0.7093 - accuracy: 0.6750 - val_loss: 0.9803 - val_accuracy: 0.4650\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 80us/sample - loss: 0.7773 - accuracy: 0.6288 - val_loss: 0.7067 - val_accuracy: 0.6400\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 76us/sample - loss: 0.5538 - accuracy: 0.7600 - val_loss: 0.7735 - val_accuracy: 0.6250\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 78us/sample - loss: 0.5541 - accuracy: 0.7613 - val_loss: 0.4171 - val_accuracy: 0.8200\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 80us/sample - loss: 0.5530 - accuracy: 0.7588 - val_loss: 0.4126 - val_accuracy: 0.8300\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 80us/sample - loss: 0.3848 - accuracy: 0.8487 - val_loss: 0.7852 - val_accuracy: 0.6600\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 79us/sample - loss: 0.4440 - accuracy: 0.8263 - val_loss: 0.4283 - val_accuracy: 0.8000\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 0.3800 - accuracy: 0.8400 - val_loss: 0.3548 - val_accuracy: 0.8600\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 76us/sample - loss: 0.3421 - accuracy: 0.8725 - val_loss: 0.3458 - val_accuracy: 0.8450\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 79us/sample - loss: 0.3811 - accuracy: 0.8338 - val_loss: 0.7140 - val_accuracy: 0.7050\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 81us/sample - loss: 0.4471 - accuracy: 0.8150 - val_loss: 0.3602 - val_accuracy: 0.8400\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 80us/sample - loss: 0.2830 - accuracy: 0.8863 - val_loss: 0.3259 - val_accuracy: 0.8650\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 84us/sample - loss: 0.2626 - accuracy: 0.9062 - val_loss: 0.2586 - val_accuracy: 0.8950\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 80us/sample - loss: 0.2661 - accuracy: 0.8913 - val_loss: 0.3689 - val_accuracy: 0.8400\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 80us/sample - loss: 0.3087 - accuracy: 0.8800 - val_loss: 0.2864 - val_accuracy: 0.8850\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 78us/sample - loss: 0.2459 - accuracy: 0.9038 - val_loss: 0.3098 - val_accuracy: 0.8650\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 77us/sample - loss: 0.2339 - accuracy: 0.9275 - val_loss: 0.2766 - val_accuracy: 0.8850\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 78us/sample - loss: 0.2317 - accuracy: 0.9225 - val_loss: 0.2489 - val_accuracy: 0.8900\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 85us/sample - loss: 0.2177 - accuracy: 0.9212 - val_loss: 0.5242 - val_accuracy: 0.7850\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 0.2330 - accuracy: 0.9075 - val_loss: 0.3048 - val_accuracy: 0.8700\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 0.1911 - accuracy: 0.9337 - val_loss: 0.2194 - val_accuracy: 0.9100\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 87us/sample - loss: 0.2803 - accuracy: 0.8800 - val_loss: 0.3026 - val_accuracy: 0.8750\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 0.1844 - accuracy: 0.9250 - val_loss: 0.3083 - val_accuracy: 0.8650\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 0.1911 - accuracy: 0.9325 - val_loss: 0.2177 - val_accuracy: 0.9050\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 0.1776 - accuracy: 0.9287 - val_loss: 0.3073 - val_accuracy: 0.8650\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 0.1945 - accuracy: 0.9287 - val_loss: 0.2359 - val_accuracy: 0.8800\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 84us/sample - loss: 0.1687 - accuracy: 0.9438 - val_loss: 0.2356 - val_accuracy: 0.9100\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 86us/sample - loss: 0.1653 - accuracy: 0.9425 - val_loss: 0.2690 - val_accuracy: 0.8900\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 85us/sample - loss: 0.1658 - accuracy: 0.9438 - val_loss: 0.2373 - val_accuracy: 0.8800\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 84us/sample - loss: 0.1758 - accuracy: 0.9287 - val_loss: 0.2393 - val_accuracy: 0.8950\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 86us/sample - loss: 0.2004 - accuracy: 0.9162 - val_loss: 0.5347 - val_accuracy: 0.8400\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 87us/sample - loss: 0.2574 - accuracy: 0.8850 - val_loss: 0.1873 - val_accuracy: 0.9200\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 84us/sample - loss: 0.1413 - accuracy: 0.9525 - val_loss: 0.1623 - val_accuracy: 0.9350\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 84us/sample - loss: 0.1336 - accuracy: 0.9488 - val_loss: 0.1948 - val_accuracy: 0.9250\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 84us/sample - loss: 0.1315 - accuracy: 0.9588 - val_loss: 0.1762 - val_accuracy: 0.9350\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 84us/sample - loss: 0.1310 - accuracy: 0.9488 - val_loss: 0.1656 - val_accuracy: 0.9350\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 84us/sample - loss: 0.1239 - accuracy: 0.9538 - val_loss: 0.1819 - val_accuracy: 0.9250\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 0.1289 - accuracy: 0.9525 - val_loss: 0.2005 - val_accuracy: 0.9150\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 0.1262 - accuracy: 0.9550 - val_loss: 0.1974 - val_accuracy: 0.9250\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 0.1548 - accuracy: 0.9413 - val_loss: 0.1693 - val_accuracy: 0.9400\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 0.1392 - accuracy: 0.9413 - val_loss: 0.4395 - val_accuracy: 0.8300\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 0.1523 - accuracy: 0.9413 - val_loss: 0.2021 - val_accuracy: 0.8850\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 87us/sample - loss: 0.1210 - accuracy: 0.9625 - val_loss: 0.1525 - val_accuracy: 0.9350\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 0.1156 - accuracy: 0.9663 - val_loss: 0.2046 - val_accuracy: 0.9150\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 79us/sample - loss: 0.1342 - accuracy: 0.9450 - val_loss: 0.1572 - val_accuracy: 0.9400\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 77us/sample - loss: 0.1943 - accuracy: 0.9175 - val_loss: 0.1476 - val_accuracy: 0.9400\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 0s 523us/sample - loss: 1.3757 - accuracy: 0.2750 - val_loss: 1.3169 - val_accuracy: 0.2850\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 79us/sample - loss: 1.2920 - accuracy: 0.3237 - val_loss: 1.2328 - val_accuracy: 0.3350\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 77us/sample - loss: 1.1590 - accuracy: 0.4663 - val_loss: 1.0230 - val_accuracy: 0.4450\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 78us/sample - loss: 0.9322 - accuracy: 0.5688 - val_loss: 1.2588 - val_accuracy: 0.1900\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 78us/sample - loss: 0.8686 - accuracy: 0.6062 - val_loss: 0.6903 - val_accuracy: 0.6500\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 80us/sample - loss: 0.7404 - accuracy: 0.6513 - val_loss: 0.9750 - val_accuracy: 0.4300\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 79us/sample - loss: 0.6277 - accuracy: 0.7287 - val_loss: 0.8288 - val_accuracy: 0.5650\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 77us/sample - loss: 0.5838 - accuracy: 0.7163 - val_loss: 0.5379 - val_accuracy: 0.7250\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 0.4577 - accuracy: 0.7975 - val_loss: 0.6588 - val_accuracy: 0.6800\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 80us/sample - loss: 0.6912 - accuracy: 0.6950 - val_loss: 0.4497 - val_accuracy: 0.8150\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 78us/sample - loss: 0.4255 - accuracy: 0.8238 - val_loss: 0.4866 - val_accuracy: 0.7750\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 80us/sample - loss: 0.3745 - accuracy: 0.8512 - val_loss: 0.4838 - val_accuracy: 0.7950\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 0.4022 - accuracy: 0.8175 - val_loss: 0.4322 - val_accuracy: 0.8100\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 0.4418 - accuracy: 0.8050 - val_loss: 0.4513 - val_accuracy: 0.8200\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 109us/sample - loss: 0.3612 - accuracy: 0.8450 - val_loss: 0.4796 - val_accuracy: 0.7800\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 0.3665 - accuracy: 0.8462 - val_loss: 0.3559 - val_accuracy: 0.8550\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 0.3186 - accuracy: 0.8675 - val_loss: 0.3401 - val_accuracy: 0.8600\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 0.2939 - accuracy: 0.8838 - val_loss: 0.4198 - val_accuracy: 0.8950\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 0.4111 - accuracy: 0.8338 - val_loss: 0.4136 - val_accuracy: 0.8150\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 0.3130 - accuracy: 0.8587 - val_loss: 0.2821 - val_accuracy: 0.8900\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 0.3060 - accuracy: 0.8737 - val_loss: 0.2949 - val_accuracy: 0.8900\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 85us/sample - loss: 0.2839 - accuracy: 0.8863 - val_loss: 0.3099 - val_accuracy: 0.8800\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 83us/sample - loss: 0.2403 - accuracy: 0.8975 - val_loss: 0.2606 - val_accuracy: 0.9200\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 84us/sample - loss: 0.3073 - accuracy: 0.8687 - val_loss: 0.2107 - val_accuracy: 0.9500\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 83us/sample - loss: 0.2215 - accuracy: 0.9075 - val_loss: 0.2745 - val_accuracy: 0.8900\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 78us/sample - loss: 0.2568 - accuracy: 0.8963 - val_loss: 0.2276 - val_accuracy: 0.9200\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 80us/sample - loss: 0.2192 - accuracy: 0.9075 - val_loss: 0.4704 - val_accuracy: 0.8100\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 82us/sample - loss: 0.2445 - accuracy: 0.9050 - val_loss: 0.2888 - val_accuracy: 0.8750\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 0.3360 - accuracy: 0.8737 - val_loss: 0.3689 - val_accuracy: 0.8350\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 87us/sample - loss: 0.2012 - accuracy: 0.9325 - val_loss: 0.5896 - val_accuracy: 0.8000\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 0.2837 - accuracy: 0.8875 - val_loss: 0.1833 - val_accuracy: 0.9400\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 0.1942 - accuracy: 0.9350 - val_loss: 0.1812 - val_accuracy: 0.9400\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 0.1767 - accuracy: 0.9337 - val_loss: 0.1636 - val_accuracy: 0.9550\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 0.1499 - accuracy: 0.9463 - val_loss: 0.2275 - val_accuracy: 0.9400\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 0.1900 - accuracy: 0.9312 - val_loss: 0.2006 - val_accuracy: 0.9450\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 0.1514 - accuracy: 0.9438 - val_loss: 0.1620 - val_accuracy: 0.9400\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 0.1568 - accuracy: 0.9425 - val_loss: 0.3015 - val_accuracy: 0.8800\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 0.1839 - accuracy: 0.9300 - val_loss: 0.1502 - val_accuracy: 0.9600\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 84us/sample - loss: 0.1401 - accuracy: 0.9525 - val_loss: 0.2142 - val_accuracy: 0.9400\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 85us/sample - loss: 0.1876 - accuracy: 0.9225 - val_loss: 0.1922 - val_accuracy: 0.9250\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 82us/sample - loss: 0.1451 - accuracy: 0.9362 - val_loss: 0.2629 - val_accuracy: 0.8700\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 80us/sample - loss: 0.1655 - accuracy: 0.9312 - val_loss: 0.1387 - val_accuracy: 0.9550\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 84us/sample - loss: 0.1592 - accuracy: 0.9413 - val_loss: 0.1806 - val_accuracy: 0.9600\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 0.1314 - accuracy: 0.9513 - val_loss: 0.1852 - val_accuracy: 0.9400\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 81us/sample - loss: 0.1289 - accuracy: 0.9513 - val_loss: 0.1309 - val_accuracy: 0.9600\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 0.1181 - accuracy: 0.9650 - val_loss: 0.1300 - val_accuracy: 0.9600\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 83us/sample - loss: 0.1115 - accuracy: 0.9650 - val_loss: 0.1262 - val_accuracy: 0.9550\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 81us/sample - loss: 0.1157 - accuracy: 0.9600 - val_loss: 0.1183 - val_accuracy: 0.9550\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 75us/sample - loss: 0.1071 - accuracy: 0.9625 - val_loss: 0.1162 - val_accuracy: 0.9500\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 77us/sample - loss: 0.1398 - accuracy: 0.9475 - val_loss: 0.1168 - val_accuracy: 0.9600\n"
     ]
    }
   ],
   "source": [
    "input_shape = (32, 32, 1)\n",
    "num_classes = 4\n",
    "cnn_model_sq = SimpleCNN.build(width=input_shape[0], height=input_shape[1], depth=input_shape[2],\n",
    "                   num_classes=num_classes)\n",
    "cnn_model_tri = SimpleCNN.build(width=input_shape[0], height=input_shape[1], depth=input_shape[2],\n",
    "                   num_classes=num_classes)\n",
    "\n",
    "CNN_hyperparams = (0.01, 50, 64)\n",
    "H_sq_CNN, sq_CNN_model = train_model(cnn_model_sq, Xsq_train, ysq_train, Xsq_test, ysq_test, num_classes, input_shape, CNN_hyperparams)\n",
    "H_tri_CNN, tri_CNN_model = train_model(cnn_model_tri, Xtri_train, ytri_train, Xtri_test, ytri_test, num_classes, input_shape, CNN_hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) We have provided a test set of 10 spins configurations for each of the two problems. Each of the spin configurations is not necessarily at the temperatures of the training sets. Calculate your best estimate of the temperatures of these spin configuration. Upload your results to Kaggle.\n",
    "[Hint: A direct fingerprint of temperature is the distribution of spin up\n",
    "and down, because you can image that the spins fluctuate more violently\n",
    "at higher temperature. Although the mothod you use in homework 2 can also work, you may be interested in trying to take distribution into account when you\n",
    "build the model to estimate temperature and see if you can make use of this extra information. This may help you win the\n",
    "kaggle. It is totally fine if you find that the information of distribution is not helpful. Note also that a CNN kind-of does this. One possibility is that you may want a CNN that captures enough distribution information.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution to (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsq_sim_data = []\\ntri_sim_data = []\\nsim_data_temp = []\\n\\nfor temp in temps_vec:    \\n    sq_ising_simu = Ising_sq(32, temp)\\n    tri_ising_simu = Ising_tri(32, temp)\\n    sq_img = sq_ising_simu.simulate()\\n    tri_img = tri_ising_simu.simulate()\\n    \\n    sq_sim_data.append(sq_img)\\n    tri_sim_data.append(tri_img)\\n    \\ncwd = str(os.getcwd())\\nsim_data_path_2 = cwd+\"/sim_data_2.npy\"\\nsim_data_temp_path_2 = cwd+\"/sim_data_temp_2.npy\"\\nsim_data_tot_lv_mean_path = cwd+\"/sim_data_tot_lv_mean.npy\"\\n\\nnp.save(sq_sim_data_path, np.asarray(sq_sim_data))\\nnp.save(tri_sim_data_path, np.asarray(tri_sim_data))\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = str(os.getcwd())\n",
    "sq_sim_data_path = cwd+\"/sq_sim_data.npy\"\n",
    "tri_sim_data_path = cwd+\"/tri_sim_data.npy\"\n",
    "\n",
    "temps_vec = np.linspace(0.01,15,num=1500)\n",
    "\n",
    "\"\"\"\n",
    "sq_sim_data = []\n",
    "tri_sim_data = []\n",
    "sim_data_temp = []\n",
    "\n",
    "for temp in temps_vec:    \n",
    "    sq_ising_simu = Ising_sq(32, temp)\n",
    "    tri_ising_simu = Ising_tri(32, temp)\n",
    "    sq_img = sq_ising_simu.simulate()\n",
    "    tri_img = tri_ising_simu.simulate()\n",
    "    \n",
    "    sq_sim_data.append(sq_img)\n",
    "    tri_sim_data.append(tri_img)\n",
    "    \n",
    "cwd = str(os.getcwd())\n",
    "sim_data_path_2 = cwd+\"/sim_data_2.npy\"\n",
    "sim_data_temp_path_2 = cwd+\"/sim_data_temp_2.npy\"\n",
    "sim_data_tot_lv_mean_path = cwd+\"/sim_data_tot_lv_mean.npy\"\n",
    "\n",
    "np.save(sq_sim_data_path, np.asarray(sq_sim_data))\n",
    "np.save(tri_sim_data_path, np.asarray(tri_sim_data))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data ready to be embedded\n",
    "sq_sim_img = np.load(sq_sim_data_path).reshape(1500,32,32,-1)\n",
    "tri_sim_img = np.load(tri_sim_data_path).reshape(1500,32,32,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_sim_img_rs, tri_sim_img_rs = np.repeat(sq_sim_img, 5, 1), np.repeat(tri_sim_img, 5, 1)\n",
    "sq_sim_img_rs, tri_sim_img_rs = np.repeat(sq_sim_img_rs, 5, 2), np.repeat(tri_sim_img_rs, 5, 2)\n",
    "sq_sim_img_rs, tri_sim_img_rs = np.repeat(sq_sim_img_rs, 3, 3), np.repeat(tri_sim_img_rs, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pre-trained MobileNetV2 \n",
    "with tf.device('/CPU:0'):\n",
    "    base_model = tf.keras.applications.MobileNetV2(input_shape=(160,160,3),\n",
    "                                                   include_top=False,\n",
    "                                                   weights='imagenet',\n",
    "                                                   classes=4)\n",
    "    base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the embedded data\n",
    "global_avg_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "\n",
    "sq_sim_data_emb = global_avg_layer(base_model.predict(sq_sim_img_rs))\n",
    "sq_sim_data_emb = sq_sim_data_emb.numpy()/sq_sim_data_emb.numpy().max()\n",
    "\n",
    "tri_sim_data_emb = global_avg_layer(base_model.predict(tri_sim_img_rs))\n",
    "tri_sim_data_emb = tri_sim_data_emb.numpy()/tri_sim_data_emb.numpy().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train/test splits\n",
    "sq_x_train, sq_x_test, sq_y_train, sq_y_test = train_test_split(sq_sim_data_emb, temps_vec, test_size=0.2, random_state=0)\n",
    "tri_x_train, tri_x_test, tri_y_train, tri_y_test = train_test_split(tri_sim_data_emb, temps_vec, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class RegressionHead:\n",
    "    def __init__(self):\n",
    "        model = self\n",
    "    \n",
    "    @staticmethod\n",
    "    def build(channels_first=False):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(612, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dropout(0.25))\n",
    "        model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dropout(0.25))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(1, activation='linear'))\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1200 samples, validate on 300 samples\n",
      "Epoch 1/50\n",
      "1200/1200 [==============================] - 1s 555us/sample - loss: 55.1380 - MeanSquaredError: 55.1380 - val_loss: 48.3800 - val_MeanSquaredError: 48.3800\n",
      "Epoch 2/50\n",
      "1200/1200 [==============================] - 0s 76us/sample - loss: 41.0185 - MeanSquaredError: 41.0185 - val_loss: 47.6785 - val_MeanSquaredError: 47.6785\n",
      "Epoch 3/50\n",
      "1200/1200 [==============================] - 0s 78us/sample - loss: 32.2175 - MeanSquaredError: 32.2175 - val_loss: 38.0394 - val_MeanSquaredError: 38.0394\n",
      "Epoch 4/50\n",
      "1200/1200 [==============================] - 0s 89us/sample - loss: 25.2200 - MeanSquaredError: 25.2200 - val_loss: 21.8155 - val_MeanSquaredError: 21.8155\n",
      "Epoch 5/50\n",
      "1200/1200 [==============================] - 0s 75us/sample - loss: 19.3599 - MeanSquaredError: 19.3599 - val_loss: 21.1247 - val_MeanSquaredError: 21.1247\n",
      "Epoch 6/50\n",
      "1200/1200 [==============================] - 0s 77us/sample - loss: 15.2664 - MeanSquaredError: 15.2664 - val_loss: 17.7490 - val_MeanSquaredError: 17.7490\n",
      "Epoch 7/50\n",
      "1200/1200 [==============================] - 0s 77us/sample - loss: 12.2131 - MeanSquaredError: 12.2131 - val_loss: 12.0315 - val_MeanSquaredError: 12.0315\n",
      "Epoch 8/50\n",
      "1200/1200 [==============================] - 0s 79us/sample - loss: 9.6683 - MeanSquaredError: 9.6683 - val_loss: 6.9873 - val_MeanSquaredError: 6.9873\n",
      "Epoch 9/50\n",
      "1200/1200 [==============================] - 0s 78us/sample - loss: 7.9075 - MeanSquaredError: 7.9075 - val_loss: 5.3768 - val_MeanSquaredError: 5.3768\n",
      "Epoch 10/50\n",
      "1200/1200 [==============================] - 0s 78us/sample - loss: 6.8129 - MeanSquaredError: 6.8129 - val_loss: 3.5707 - val_MeanSquaredError: 3.5707\n",
      "Epoch 11/50\n",
      "1200/1200 [==============================] - 0s 81us/sample - loss: 6.0616 - MeanSquaredError: 6.0616 - val_loss: 8.8026 - val_MeanSquaredError: 8.8026\n",
      "Epoch 12/50\n",
      "1200/1200 [==============================] - 0s 84us/sample - loss: 5.2790 - MeanSquaredError: 5.2790 - val_loss: 4.5310 - val_MeanSquaredError: 4.5310\n",
      "Epoch 13/50\n",
      "1200/1200 [==============================] - 0s 84us/sample - loss: 5.0387 - MeanSquaredError: 5.0387 - val_loss: 3.5462 - val_MeanSquaredError: 3.5462\n",
      "Epoch 14/50\n",
      "1200/1200 [==============================] - 0s 91us/sample - loss: 4.8690 - MeanSquaredError: 4.8690 - val_loss: 3.9930 - val_MeanSquaredError: 3.9930\n",
      "Epoch 15/50\n",
      "1200/1200 [==============================] - 0s 82us/sample - loss: 4.6469 - MeanSquaredError: 4.6469 - val_loss: 3.4552 - val_MeanSquaredError: 3.4552\n",
      "Epoch 16/50\n",
      "1200/1200 [==============================] - 0s 83us/sample - loss: 4.4669 - MeanSquaredError: 4.4669 - val_loss: 4.0627 - val_MeanSquaredError: 4.0627\n",
      "Epoch 17/50\n",
      "1200/1200 [==============================] - 0s 74us/sample - loss: 4.3871 - MeanSquaredError: 4.3871 - val_loss: 3.0391 - val_MeanSquaredError: 3.0391\n",
      "Epoch 18/50\n",
      "1200/1200 [==============================] - 0s 73us/sample - loss: 4.4579 - MeanSquaredError: 4.4579 - val_loss: 3.4953 - val_MeanSquaredError: 3.4953\n",
      "Epoch 19/50\n",
      "1200/1200 [==============================] - 0s 74us/sample - loss: 4.3641 - MeanSquaredError: 4.3641 - val_loss: 3.0566 - val_MeanSquaredError: 3.0566\n",
      "Epoch 20/50\n",
      "1200/1200 [==============================] - 0s 72us/sample - loss: 4.2131 - MeanSquaredError: 4.2131 - val_loss: 3.6550 - val_MeanSquaredError: 3.6550\n",
      "Epoch 21/50\n",
      "1200/1200 [==============================] - 0s 76us/sample - loss: 4.2691 - MeanSquaredError: 4.2691 - val_loss: 3.8825 - val_MeanSquaredError: 3.8825\n",
      "Epoch 22/50\n",
      "1200/1200 [==============================] - 0s 75us/sample - loss: 4.1357 - MeanSquaredError: 4.1357 - val_loss: 3.2740 - val_MeanSquaredError: 3.2740\n",
      "Epoch 23/50\n",
      "1200/1200 [==============================] - 0s 80us/sample - loss: 3.9110 - MeanSquaredError: 3.9110 - val_loss: 3.0126 - val_MeanSquaredError: 3.0126\n",
      "Epoch 24/50\n",
      "1200/1200 [==============================] - 0s 85us/sample - loss: 4.2097 - MeanSquaredError: 4.2097 - val_loss: 3.0383 - val_MeanSquaredError: 3.0383\n",
      "Epoch 25/50\n",
      "1200/1200 [==============================] - 0s 89us/sample - loss: 4.3222 - MeanSquaredError: 4.3222 - val_loss: 2.9683 - val_MeanSquaredError: 2.9683\n",
      "Epoch 26/50\n",
      "1200/1200 [==============================] - 0s 74us/sample - loss: 3.9191 - MeanSquaredError: 3.9191 - val_loss: 3.1051 - val_MeanSquaredError: 3.1051\n",
      "Epoch 27/50\n",
      "1200/1200 [==============================] - 0s 79us/sample - loss: 4.2670 - MeanSquaredError: 4.2670 - val_loss: 3.1288 - val_MeanSquaredError: 3.1288\n",
      "Epoch 28/50\n",
      "1200/1200 [==============================] - 0s 77us/sample - loss: 4.0772 - MeanSquaredError: 4.0772 - val_loss: 3.5071 - val_MeanSquaredError: 3.5071\n",
      "Epoch 29/50\n",
      "1200/1200 [==============================] - 0s 75us/sample - loss: 3.8748 - MeanSquaredError: 3.8748 - val_loss: 3.7478 - val_MeanSquaredError: 3.7478\n",
      "Epoch 30/50\n",
      "1200/1200 [==============================] - 0s 76us/sample - loss: 3.9814 - MeanSquaredError: 3.9814 - val_loss: 2.9735 - val_MeanSquaredError: 2.9735\n",
      "Epoch 31/50\n",
      "1200/1200 [==============================] - 0s 77us/sample - loss: 3.9403 - MeanSquaredError: 3.9403 - val_loss: 3.0628 - val_MeanSquaredError: 3.0628\n",
      "Epoch 32/50\n",
      "1200/1200 [==============================] - 0s 77us/sample - loss: 4.0167 - MeanSquaredError: 4.0167 - val_loss: 3.0708 - val_MeanSquaredError: 3.0708\n",
      "Epoch 33/50\n",
      "1200/1200 [==============================] - 0s 82us/sample - loss: 4.1995 - MeanSquaredError: 4.1995 - val_loss: 3.1021 - val_MeanSquaredError: 3.1021\n",
      "Epoch 34/50\n",
      "1200/1200 [==============================] - 0s 81us/sample - loss: 3.9783 - MeanSquaredError: 3.9783 - val_loss: 4.9327 - val_MeanSquaredError: 4.9327\n",
      "Epoch 35/50\n",
      "1200/1200 [==============================] - 0s 92us/sample - loss: 3.9043 - MeanSquaredError: 3.9043 - val_loss: 2.9629 - val_MeanSquaredError: 2.9629\n",
      "Epoch 36/50\n",
      "1200/1200 [==============================] - 0s 79us/sample - loss: 3.8265 - MeanSquaredError: 3.8265 - val_loss: 3.0852 - val_MeanSquaredError: 3.0852\n",
      "Epoch 37/50\n",
      "1200/1200 [==============================] - 0s 72us/sample - loss: 3.8953 - MeanSquaredError: 3.8953 - val_loss: 3.8461 - val_MeanSquaredError: 3.8461\n",
      "Epoch 38/50\n",
      "1200/1200 [==============================] - 0s 71us/sample - loss: 3.6987 - MeanSquaredError: 3.6987 - val_loss: 3.1362 - val_MeanSquaredError: 3.1362\n",
      "Epoch 39/50\n",
      "1200/1200 [==============================] - 0s 77us/sample - loss: 3.7687 - MeanSquaredError: 3.7687 - val_loss: 3.1070 - val_MeanSquaredError: 3.1070\n",
      "Epoch 40/50\n",
      "1200/1200 [==============================] - 0s 72us/sample - loss: 3.8549 - MeanSquaredError: 3.8549 - val_loss: 5.1295 - val_MeanSquaredError: 5.1295\n",
      "Epoch 41/50\n",
      "1200/1200 [==============================] - 0s 72us/sample - loss: 3.8055 - MeanSquaredError: 3.8055 - val_loss: 3.0911 - val_MeanSquaredError: 3.0911\n",
      "Epoch 42/50\n",
      "1200/1200 [==============================] - 0s 76us/sample - loss: 3.7764 - MeanSquaredError: 3.7764 - val_loss: 3.4776 - val_MeanSquaredError: 3.4776\n",
      "Epoch 43/50\n",
      "1200/1200 [==============================] - 0s 83us/sample - loss: 3.5817 - MeanSquaredError: 3.5817 - val_loss: 3.1991 - val_MeanSquaredError: 3.1991\n",
      "Epoch 44/50\n",
      "1200/1200 [==============================] - 0s 75us/sample - loss: 3.6708 - MeanSquaredError: 3.6708 - val_loss: 3.0521 - val_MeanSquaredError: 3.0521\n",
      "Epoch 45/50\n",
      "1200/1200 [==============================] - 0s 77us/sample - loss: 3.7106 - MeanSquaredError: 3.7106 - val_loss: 3.6894 - val_MeanSquaredError: 3.6894\n",
      "Epoch 46/50\n",
      "1200/1200 [==============================] - 0s 89us/sample - loss: 3.3119 - MeanSquaredError: 3.3119 - val_loss: 2.9649 - val_MeanSquaredError: 2.9649\n",
      "Epoch 47/50\n",
      "1200/1200 [==============================] - 0s 78us/sample - loss: 3.7362 - MeanSquaredError: 3.7362 - val_loss: 4.1911 - val_MeanSquaredError: 4.1911\n",
      "Epoch 48/50\n",
      "1200/1200 [==============================] - 0s 81us/sample - loss: 3.8204 - MeanSquaredError: 3.8204 - val_loss: 3.0651 - val_MeanSquaredError: 3.0651\n",
      "Epoch 49/50\n",
      "1200/1200 [==============================] - 0s 78us/sample - loss: 3.4878 - MeanSquaredError: 3.4878 - val_loss: 3.5466 - val_MeanSquaredError: 3.5466\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 0s 79us/sample - loss: 3.8450 - MeanSquaredError: 3.8450 - val_loss: 4.6188 - val_MeanSquaredError: 4.6188\n"
     ]
    }
   ],
   "source": [
    "INIT_LR = 0.01# learning rate\n",
    "EPOCHS = 50 # number of epochs\n",
    "BS = 32 # batch size\n",
    "OPT = optimizers.Adagrad(lr=INIT_LR) # optimizing function\n",
    "LOSS = keras.losses.MeanSquaredError()\n",
    "\n",
    "sq_reg_model = RegressionHead.build()\n",
    "sq_reg_model.compile(optimizer=OPT, loss=LOSS, metrics=['MeanSquaredError'])\n",
    "sq_reg_H = sq_reg_model.fit(sq_x_train, sq_y_train, validation_data=(sq_x_test, sq_y_test), epochs=EPOCHS,\n",
    "                  batch_size=BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1200 samples, validate on 300 samples\n",
      "Epoch 1/50\n",
      "1200/1200 [==============================] - 0s 373us/sample - loss: 52.5781 - MeanSquaredError: 52.5781 - val_loss: 46.2019 - val_MeanSquaredError: 46.2019\n",
      "Epoch 2/50\n",
      "1200/1200 [==============================] - 0s 81us/sample - loss: 39.2319 - MeanSquaredError: 39.2319 - val_loss: 36.2275 - val_MeanSquaredError: 36.2275\n",
      "Epoch 3/50\n",
      "1200/1200 [==============================] - 0s 78us/sample - loss: 29.8982 - MeanSquaredError: 29.8982 - val_loss: 31.5353 - val_MeanSquaredError: 31.5353\n",
      "Epoch 4/50\n",
      "1200/1200 [==============================] - 0s 79us/sample - loss: 22.9369 - MeanSquaredError: 22.9369 - val_loss: 26.8321 - val_MeanSquaredError: 26.8321\n",
      "Epoch 5/50\n",
      "1200/1200 [==============================] - 0s 78us/sample - loss: 17.5142 - MeanSquaredError: 17.5142 - val_loss: 18.4955 - val_MeanSquaredError: 18.4955\n",
      "Epoch 6/50\n",
      "1200/1200 [==============================] - 0s 74us/sample - loss: 13.8613 - MeanSquaredError: 13.8613 - val_loss: 16.1651 - val_MeanSquaredError: 16.1651\n",
      "Epoch 7/50\n",
      "1200/1200 [==============================] - 0s 72us/sample - loss: 11.0519 - MeanSquaredError: 11.0519 - val_loss: 9.4677 - val_MeanSquaredError: 9.4677\n",
      "Epoch 8/50\n",
      "1200/1200 [==============================] - 0s 74us/sample - loss: 8.5148 - MeanSquaredError: 8.5148 - val_loss: 6.5422 - val_MeanSquaredError: 6.5422\n",
      "Epoch 9/50\n",
      "1200/1200 [==============================] - 0s 74us/sample - loss: 7.1458 - MeanSquaredError: 7.1458 - val_loss: 9.1191 - val_MeanSquaredError: 9.1191\n",
      "Epoch 10/50\n",
      "1200/1200 [==============================] - 0s 79us/sample - loss: 6.1809 - MeanSquaredError: 6.1809 - val_loss: 3.6445 - val_MeanSquaredError: 3.6445\n",
      "Epoch 11/50\n",
      "1200/1200 [==============================] - 0s 74us/sample - loss: 5.4390 - MeanSquaredError: 5.4390 - val_loss: 3.9419 - val_MeanSquaredError: 3.9419\n",
      "Epoch 12/50\n",
      "1200/1200 [==============================] - 0s 72us/sample - loss: 4.8986 - MeanSquaredError: 4.8986 - val_loss: 3.7188 - val_MeanSquaredError: 3.7188\n",
      "Epoch 13/50\n",
      "1200/1200 [==============================] - 0s 79us/sample - loss: 4.4667 - MeanSquaredError: 4.4667 - val_loss: 5.3109 - val_MeanSquaredError: 5.3109\n",
      "Epoch 14/50\n",
      "1200/1200 [==============================] - 0s 74us/sample - loss: 4.0998 - MeanSquaredError: 4.0998 - val_loss: 2.1552 - val_MeanSquaredError: 2.1552\n",
      "Epoch 15/50\n",
      "1200/1200 [==============================] - 0s 81us/sample - loss: 3.6021 - MeanSquaredError: 3.6021 - val_loss: 1.7251 - val_MeanSquaredError: 1.7251\n",
      "Epoch 16/50\n",
      "1200/1200 [==============================] - 0s 80us/sample - loss: 3.5103 - MeanSquaredError: 3.5103 - val_loss: 1.8746 - val_MeanSquaredError: 1.8746\n",
      "Epoch 17/50\n",
      "1200/1200 [==============================] - 0s 76us/sample - loss: 3.5991 - MeanSquaredError: 3.5991 - val_loss: 2.8931 - val_MeanSquaredError: 2.8931\n",
      "Epoch 18/50\n",
      "1200/1200 [==============================] - 0s 73us/sample - loss: 3.6034 - MeanSquaredError: 3.6034 - val_loss: 2.0302 - val_MeanSquaredError: 2.0302\n",
      "Epoch 19/50\n",
      "1200/1200 [==============================] - 0s 76us/sample - loss: 3.2109 - MeanSquaredError: 3.2109 - val_loss: 2.1801 - val_MeanSquaredError: 2.1801\n",
      "Epoch 20/50\n",
      "1200/1200 [==============================] - 0s 81us/sample - loss: 3.6039 - MeanSquaredError: 3.6039 - val_loss: 1.7491 - val_MeanSquaredError: 1.7491\n",
      "Epoch 21/50\n",
      "1200/1200 [==============================] - 0s 85us/sample - loss: 3.7020 - MeanSquaredError: 3.7020 - val_loss: 2.0736 - val_MeanSquaredError: 2.0736\n",
      "Epoch 22/50\n",
      "1200/1200 [==============================] - 0s 85us/sample - loss: 3.4286 - MeanSquaredError: 3.4286 - val_loss: 1.6808 - val_MeanSquaredError: 1.6808\n",
      "Epoch 23/50\n",
      "1200/1200 [==============================] - 0s 88us/sample - loss: 3.2945 - MeanSquaredError: 3.2945 - val_loss: 2.0668 - val_MeanSquaredError: 2.0668\n",
      "Epoch 24/50\n",
      "1200/1200 [==============================] - 0s 86us/sample - loss: 3.2011 - MeanSquaredError: 3.2011 - val_loss: 1.9077 - val_MeanSquaredError: 1.9077\n",
      "Epoch 25/50\n",
      "1200/1200 [==============================] - 0s 80us/sample - loss: 3.6755 - MeanSquaredError: 3.6755 - val_loss: 2.0117 - val_MeanSquaredError: 2.0117\n",
      "Epoch 26/50\n",
      "1200/1200 [==============================] - 0s 85us/sample - loss: 2.8987 - MeanSquaredError: 2.8987 - val_loss: 1.7875 - val_MeanSquaredError: 1.7875\n",
      "Epoch 27/50\n",
      "1200/1200 [==============================] - 0s 85us/sample - loss: 3.1229 - MeanSquaredError: 3.1229 - val_loss: 1.7162 - val_MeanSquaredError: 1.7162\n",
      "Epoch 28/50\n",
      "1200/1200 [==============================] - 0s 83us/sample - loss: 3.2071 - MeanSquaredError: 3.2071 - val_loss: 1.6594 - val_MeanSquaredError: 1.6594\n",
      "Epoch 29/50\n",
      "1200/1200 [==============================] - 0s 78us/sample - loss: 3.4438 - MeanSquaredError: 3.4438 - val_loss: 1.8599 - val_MeanSquaredError: 1.8599\n",
      "Epoch 30/50\n",
      "1200/1200 [==============================] - 0s 77us/sample - loss: 3.3555 - MeanSquaredError: 3.3555 - val_loss: 1.9769 - val_MeanSquaredError: 1.9769\n",
      "Epoch 31/50\n",
      "1200/1200 [==============================] - 0s 80us/sample - loss: 3.2935 - MeanSquaredError: 3.2935 - val_loss: 1.8481 - val_MeanSquaredError: 1.8481\n",
      "Epoch 32/50\n",
      "1200/1200 [==============================] - 0s 81us/sample - loss: 3.1326 - MeanSquaredError: 3.1326 - val_loss: 1.7701 - val_MeanSquaredError: 1.7701\n",
      "Epoch 33/50\n",
      "1200/1200 [==============================] - 0s 78us/sample - loss: 3.0422 - MeanSquaredError: 3.0422 - val_loss: 1.8933 - val_MeanSquaredError: 1.8933\n",
      "Epoch 34/50\n",
      "1200/1200 [==============================] - 0s 78us/sample - loss: 3.3343 - MeanSquaredError: 3.3343 - val_loss: 2.0502 - val_MeanSquaredError: 2.0502\n",
      "Epoch 35/50\n",
      "1200/1200 [==============================] - 0s 79us/sample - loss: 2.9907 - MeanSquaredError: 2.9907 - val_loss: 2.1843 - val_MeanSquaredError: 2.1843\n",
      "Epoch 36/50\n",
      "1200/1200 [==============================] - 0s 92us/sample - loss: 3.4993 - MeanSquaredError: 3.4993 - val_loss: 1.7502 - val_MeanSquaredError: 1.7502\n",
      "Epoch 37/50\n",
      "1200/1200 [==============================] - 0s 77us/sample - loss: 3.0685 - MeanSquaredError: 3.0685 - val_loss: 1.9192 - val_MeanSquaredError: 1.9192\n",
      "Epoch 38/50\n",
      "1200/1200 [==============================] - 0s 77us/sample - loss: 2.9644 - MeanSquaredError: 2.9644 - val_loss: 1.8845 - val_MeanSquaredError: 1.8845\n",
      "Epoch 39/50\n",
      "1200/1200 [==============================] - 0s 72us/sample - loss: 2.9201 - MeanSquaredError: 2.9201 - val_loss: 1.9204 - val_MeanSquaredError: 1.9204\n",
      "Epoch 40/50\n",
      "1200/1200 [==============================] - 0s 84us/sample - loss: 2.9531 - MeanSquaredError: 2.9531 - val_loss: 2.6273 - val_MeanSquaredError: 2.6273\n",
      "Epoch 41/50\n",
      "1200/1200 [==============================] - 0s 89us/sample - loss: 3.2907 - MeanSquaredError: 3.2907 - val_loss: 1.6796 - val_MeanSquaredError: 1.6796\n",
      "Epoch 42/50\n",
      "1200/1200 [==============================] - 0s 86us/sample - loss: 3.0060 - MeanSquaredError: 3.0060 - val_loss: 2.0972 - val_MeanSquaredError: 2.0972\n",
      "Epoch 43/50\n",
      "1200/1200 [==============================] - 0s 88us/sample - loss: 3.1087 - MeanSquaredError: 3.1087 - val_loss: 2.0878 - val_MeanSquaredError: 2.0878\n",
      "Epoch 44/50\n",
      "1200/1200 [==============================] - 0s 86us/sample - loss: 2.8091 - MeanSquaredError: 2.8091 - val_loss: 1.5979 - val_MeanSquaredError: 1.5979\n",
      "Epoch 45/50\n",
      "1200/1200 [==============================] - 0s 78us/sample - loss: 2.9909 - MeanSquaredError: 2.9909 - val_loss: 1.6273 - val_MeanSquaredError: 1.6273\n",
      "Epoch 46/50\n",
      "1200/1200 [==============================] - 0s 75us/sample - loss: 3.0507 - MeanSquaredError: 3.0507 - val_loss: 1.6457 - val_MeanSquaredError: 1.6457\n",
      "Epoch 47/50\n",
      "1200/1200 [==============================] - 0s 79us/sample - loss: 3.1196 - MeanSquaredError: 3.1196 - val_loss: 1.6480 - val_MeanSquaredError: 1.6480\n",
      "Epoch 48/50\n",
      "1200/1200 [==============================] - 0s 84us/sample - loss: 3.2092 - MeanSquaredError: 3.2092 - val_loss: 1.8157 - val_MeanSquaredError: 1.8157\n",
      "Epoch 49/50\n",
      "1200/1200 [==============================] - 0s 84us/sample - loss: 3.0685 - MeanSquaredError: 3.0685 - val_loss: 2.1077 - val_MeanSquaredError: 2.1077\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 0s 86us/sample - loss: 3.0658 - MeanSquaredError: 3.0658 - val_loss: 1.8976 - val_MeanSquaredError: 1.8976\n"
     ]
    }
   ],
   "source": [
    "INIT_LR = 0.01# learning rate\n",
    "EPOCHS = 50 # number of epochs\n",
    "BS = 32 # batch size\n",
    "OPT = optimizers.Adagrad(lr=INIT_LR) # optimizing function\n",
    "LOSS = keras.losses.MeanSquaredError()\n",
    "\n",
    "tri_reg_model = RegressionHead.build()\n",
    "tri_reg_model.compile(optimizer=OPT, loss=LOSS, metrics=['MeanSquaredError'])\n",
    "tri_reg_H = tri_reg_model.fit(tri_x_train, tri_y_train, validation_data=(tri_x_test, tri_y_test), epochs=EPOCHS,\n",
    "                  batch_size=BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_sim_data_probas = sq_CNN_model.predict_proba(sq_sim_img)\n",
    "tri_sim_data_probas = sq_CNN_model.predict_proba(tri_sim_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def T_import(dir):\n",
    "    temp = []\n",
    "    for i in range(len(os.listdir(dir+'/'))):\n",
    "        temp.append(np.loadtxt((dir+'/')+str(i).zfill(3), delimiter=','))\n",
    "    return np.array(temp)\n",
    "\n",
    "def T10_import(dir):\n",
    "    temp = []\n",
    "    for i in range(0,10):\n",
    "        for j in range(0,10):\n",
    "            temp.append(np.loadtxt((dir+'/T0'+str(i)+'#')+str(j).zfill(2), delimiter=','))\n",
    "    return np.array(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_t10_img = T10_import(cwd+'/triangle_10T').reshape(100,32,32,-1)\n",
    "sq_t10_img = T10_import(cwd+'/square_10T').reshape(100,32,32,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_t10_img_rs, tri_t10_img_rs = np.repeat(sq_t10_img, 5, 1), np.repeat(tri_t10_img, 5, 1)\n",
    "sq_t10_img_rs, tri_t10_img_rs = np.repeat(sq_t10_img_rs, 5, 2), np.repeat(tri_t10_img_rs, 5, 2)\n",
    "sq_t10_img_rs, tri_t10_img_rs = np.repeat(sq_t10_img_rs, 3, 3), np.repeat(tri_t10_img_rs, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_t10_data_emb = global_avg_layer(base_model.predict(sq_t10_img_rs))\n",
    "sq_t10_data_emb = sq_t10_data_emb.numpy()/sq_t10_data_emb.numpy().max()\n",
    "\n",
    "tri_t10_data_emb = global_avg_layer(base_model.predict(tri_t10_img_rs))\n",
    "tri_t10_data_emb = tri_t10_data_emb.numpy()/tri_t10_data_emb.numpy().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "pca = PCA(n_components=2)\n",
    "tsne_img_emb = tsne.fit_transform(tri_t10_data_emb)\n",
    "pca_img_emb = pca.fit_transform(tri_t10_data_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    plt.plot(tsne_img_emb.transpose()[0],tsne_img_emb.transpose()[1],'.',markersize=12)\n",
    "plt.title(\"TSNE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    plt.plot(pca_img_emb.transpose()[0], pca_img_emb.transpose()[1],'.',markersize=12)\n",
    "plt.title(\"PCA\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_pred_temps = tri_reg_model.predict(tri_t10_data_emb).reshape(10,-1)\n",
    "sq_pred_temps = tri_reg_model.predict(sq_t10_data_emb).reshape(10,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tri_class_probas = tri_CNN_model.predict_proba(tri_t10_img).reshape(10,-1,4)\n",
    "all_sq_class_probas = sq_CNN_model.predict_proba(sq_t10_img).reshape(10,-1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_tri_class_probas = np.mean(all_tri_class_probas, axis=1)\n",
    "avg_sq_class_probas = np.mean(all_sq_class_probas, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "tri_temp_list = []\n",
    "sq_temp_list = []\n",
    "\n",
    "for proba in avg_tri_class_probas:\n",
    "    dist_list = []\n",
    "    for proba_2 in tri_sim_data_probas:\n",
    "        dist_list.append(distance.euclidean(proba, proba_2))\n",
    "    max_idx = dist_list.index(min(dist_list))\n",
    "    tri_temp_list.append(temps_vec[max_idx])\n",
    "    \n",
    "for proba in avg_sq_class_probas:\n",
    "    dist_list = []\n",
    "    for proba_2 in sq_sim_data_probas:\n",
    "        dist_list.append(distance.euclidean(proba, proba_2))\n",
    "    max_idx = dist_list.index(min(dist_list))\n",
    "    sq_temp_list.append(temps_vec[max_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.47,\n",
       " 2.53,\n",
       " 2.1199999999999997,\n",
       " 1.23,\n",
       " 0.5800000000000001,\n",
       " 2.94,\n",
       " 2.8299999999999996,\n",
       " 1.9100000000000001,\n",
       " 3.86,\n",
       " 1.35]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq_temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.89,\n",
       " 3.59,\n",
       " 4.28,\n",
       " 3.8899999999999997,\n",
       " 4.4399999999999995,\n",
       " 4.43,\n",
       " 4.79,\n",
       " 2.42,\n",
       " 5.06,\n",
       " 3.1399999999999997]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tri_temp_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) *Transfer Learning*.  \n",
    "As we emphasize in class, one can freeze the training of the bottom layers of a network and retrain the top part of the network to adopt to a new situation. Use your CNN that you trained on the squarelattice data to do transfer learning on the triangular lattice data.  How does the performance compare to that of the direct methods?  Add the performance numbers for transfer learning in your table from Part (a). Note that the training time and number of training examples needed for transfer learning is far less than that for the direct  optimization. For  example,  is  50  triangle  example  sufficient  for the re-training process?  Use your transfer learning result to predict the transition temperature of triangle lattice Ising model, as demonstrated in this [Nature Physics](https://www-nature-com.ezp-prod1.hul.harvard.edu/articles/nphys4035.pdf) publication.\n",
    "\n",
    "As a guideline, you may like to just change the last `Dense` layer with `softmax` activation when you do the transfer learning. Other choices are also OK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T16:51:16.394160Z",
     "start_time": "2020-02-24T16:51:16.390887Z"
    }
   },
   "source": [
    "Solution to (d):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = sq_CNN_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                65600     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 122,116\n",
      "Trainable params: 122,116\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_layers = base_model.layers[0:5]\n",
    "trainable_layers = [\n",
    "     Flatten(),\n",
    "     Dropout(0.25),\n",
    "     Dense(32, activation='relu'),\n",
    "     Dense(num_classes, activation='softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 32)                32800     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 89,188\n",
      "Trainable params: 89,188\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "trans_model = keras.Sequential(base_layers+trainable_layers)\n",
    "trans_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/25\n",
      "800/800 [==============================] - 0s 456us/sample - loss: 0.7291 - accuracy: 0.6862 - val_loss: 0.4746 - val_accuracy: 0.8000\n",
      "Epoch 2/25\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 0.4772 - accuracy: 0.7825 - val_loss: 1.2475 - val_accuracy: 0.3600\n",
      "Epoch 3/25\n",
      "800/800 [==============================] - 0s 116us/sample - loss: 0.3944 - accuracy: 0.8363 - val_loss: 0.4983 - val_accuracy: 0.7600\n",
      "Epoch 4/25\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 0.3043 - accuracy: 0.8737 - val_loss: 0.2966 - val_accuracy: 0.8850\n",
      "Epoch 5/25\n",
      "800/800 [==============================] - 0s 106us/sample - loss: 0.2616 - accuracy: 0.8900 - val_loss: 0.3586 - val_accuracy: 0.8600\n",
      "Epoch 6/25\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 0.2762 - accuracy: 0.8863 - val_loss: 0.2119 - val_accuracy: 0.9300\n",
      "Epoch 7/25\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 0.2361 - accuracy: 0.9000 - val_loss: 0.2551 - val_accuracy: 0.9150\n",
      "Epoch 8/25\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 0.2055 - accuracy: 0.9275 - val_loss: 0.2553 - val_accuracy: 0.9100\n",
      "Epoch 9/25\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 0.2282 - accuracy: 0.9062 - val_loss: 0.1779 - val_accuracy: 0.9500\n",
      "Epoch 10/25\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 0.1631 - accuracy: 0.9463 - val_loss: 0.1640 - val_accuracy: 0.9550\n",
      "Epoch 11/25\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 0.1652 - accuracy: 0.9413 - val_loss: 0.1521 - val_accuracy: 0.9450\n",
      "Epoch 12/25\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 0.1538 - accuracy: 0.9500 - val_loss: 0.1467 - val_accuracy: 0.9550\n",
      "Epoch 13/25\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 0.2107 - accuracy: 0.9275 - val_loss: 0.1362 - val_accuracy: 0.9550\n",
      "Epoch 14/25\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 0.1527 - accuracy: 0.9325 - val_loss: 0.1144 - val_accuracy: 0.9600\n",
      "Epoch 15/25\n",
      "800/800 [==============================] - 0s 118us/sample - loss: 0.1315 - accuracy: 0.9525 - val_loss: 0.1313 - val_accuracy: 0.9500\n",
      "Epoch 16/25\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 0.1166 - accuracy: 0.9563 - val_loss: 0.1061 - val_accuracy: 0.9600\n",
      "Epoch 17/25\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 0.1347 - accuracy: 0.9488 - val_loss: 0.1222 - val_accuracy: 0.9600\n",
      "Epoch 18/25\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 0.1423 - accuracy: 0.9500 - val_loss: 0.1386 - val_accuracy: 0.9650\n",
      "Epoch 19/25\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 0.0957 - accuracy: 0.9675 - val_loss: 0.1726 - val_accuracy: 0.9650\n",
      "Epoch 20/25\n",
      "800/800 [==============================] - 0s 106us/sample - loss: 0.1211 - accuracy: 0.9550 - val_loss: 0.1077 - val_accuracy: 0.9650\n",
      "Epoch 21/25\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 0.0837 - accuracy: 0.9712 - val_loss: 0.1012 - val_accuracy: 0.9650\n",
      "Epoch 22/25\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.0838 - accuracy: 0.9675 - val_loss: 0.1324 - val_accuracy: 0.9700\n",
      "Epoch 23/25\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.1024 - accuracy: 0.9650 - val_loss: 0.1063 - val_accuracy: 0.9600\n",
      "Epoch 24/25\n",
      "800/800 [==============================] - 0s 104us/sample - loss: 0.0745 - accuracy: 0.9688 - val_loss: 0.1095 - val_accuracy: 0.9750\n",
      "Epoch 25/25\n",
      "800/800 [==============================] - 0s 104us/sample - loss: 0.0830 - accuracy: 0.9725 - val_loss: 0.1057 - val_accuracy: 0.9700\n"
     ]
    }
   ],
   "source": [
    "input_shape = (32, 32, 1)\n",
    "num_classes = 4\n",
    "hyperparams = (0.01, 25, 32)\n",
    "H_trans, trained_trans_model = train_model(trans_model, Xtri_train, ytri_train, Xtri_test, ytri_test, num_classes, input_shape, hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_ests = trained_trans_model.predict_proba(tri_sim_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_from_chance = []\n",
    "for proba in proba_ests:\n",
    "    dist_from_chance.append(distance.euclidean(proba,[0.25, 0.25, 0.25, 0.25]))\n",
    "    \n",
    "min_idx = dist_from_chance.index(min(dist_from_chance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Transition Tempurature: 2.94\n"
     ]
    }
   ],
   "source": [
    "print(\"Estimated Transition Tempurature:\", temps_vec[min_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f241c0cce10>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(proba_ests[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f241c09e310>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(proba_ests[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f23fc7c24d0>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(proba_ests[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f23fc7a8610>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAATMklEQVR4nO3de5CddX3H8fc3u4EICQbJcsvFBBqw8QpsEe+xXkjwEjvT6YAiSnUyWHFsO47EodJ27B9Fe3EckEwGqfVSmY5STGkU26roaLEEK5CAgRWELEFYQDBcw5Jv/zgPeNg9u/uczdmc5zz7fs3s7Hluu59Ncj757e88z3kiM5Ek9b453Q4gSeoMC12SasJCl6SasNAlqSYsdEmqif5ufeNFixbl8uXLu/XtJaknXX/99fdn5kCrbV0r9OXLl7N169ZufXtJ6kkRcedE25xykaSasNAlqSYsdEmqCQtdkmrCQpekmpiy0CPisoi4LyK2TbA9IuJzETEUETdGxImdjylJmkqZEfoXgTWTbF8LrCw+1gOX7HssSVK7pjwPPTN/EBHLJ9llHfClbLwP77URsTAijsrMezqUUTPsocf28PhTT7P7iVHmH9jPgnn9/PC2+1mx6GCuunEXB/b3sfuJp/jR0AO8ZPEhPPjoHgYWzOPmXQ9z3BEL2PXw48yJ4NXHLuLxPaONLxpBAHsz6Z8zh6f37u3qzyhVyeDyF/D641peG7RPOnFh0WJgZ9PycLFuXKFHxHoao3iWLVvWgW+tfTGy+0n+4sqb+NHQAzzy5GipY26+5zfPWb5h+OFnH//wtvsnPTai/YxSHZ3zhmMrW+itnqYt75qRmZuATQCDg4PeWaPLLvrubVy9/d62jzv+iAXsuHc3AAvm9bP7icZ/Bhe9+wROffGRzO377Uzeo0+OMm9uH31zbHNppnXiLJdhYGnT8hJgVwe+rmZYTGPIvPCguXxo9bEArHnxkdxwwVs57OADADjykHnPKXOAgw/st8yl/aQThb4ZOKs42+UU4GHnz+srgHlz+wAY3ZvMmRMsPGguwLgyl7R/TTnlEhFfA1YDiyJiGPhLYC5AZm4EtgCnAUPAY8DZMxVWnTWdOe2IYGBBY0S+5+nnvtBpoUvdVeYslzOm2J7AhzuWSJUWwAlLD+VPVh/LHw0ufc62uX1OrUjd1LW3z1X3RcvXs6c2Z07w8TUvGv/17HOpq/wdeRab3pRL53NI6gwLfRabXjePP6p/jv+MpCpwykVtaTVCv+TME/nKtXdxzKL5+z+QpGdZ6LPYtKZcWqw7ZmA+F7xj1T7nkbRv/F15FpszjUZ3Dl2qLgt9NptGOV/w9hd3PoekjrDQ1ZaXLn5+tyNImoCFPotN9zx0SdVkoc9inocu1YuFPovZzVK9WOhqiyN0qbos9Flsuu+2KKmaLPRZbDovilrnUnVZ6GqLA3Spuiz0WWx6l/7b6FJVWeizWHqbbqlWLPRZ7KLvDbV9jFMuUnX5bouz0J0PPMro3ukNz+1zqbos9FnoDZ/5/vQPttGlynLKRW3xRVGpuix0tcU5dKm6LHS1xT6XqstCV1u89F+qLgtdkmrCQldbHJ9L1WWhqy3OuEjVZaGrLZ62KFWXha722OdSZVnoaotTLlJ1Wehqi30uVVepQo+INRGxIyKGImJDi+3Pj4h/j4gbImJ7RJzd+aiSpMlMWegR0QdcDKwFVgFnRMSqMbt9GLg5M18OrAb+PiIO6HBWVYAXFknVVWaEfjIwlJm3Z+Ye4HJg3Zh9ElgQjWf7fOBBYLSjSVUJ1rlUXWUKfTGws2l5uFjX7CLgd4FdwE3ARzNz79gvFBHrI2JrRGwdGRmZZmR1kwN0qbrKFHqrp/DYuyOcCvwMOBp4BXBRRBwy7qDMTZk5mJmDAwMDbYdV93keulRdZQp9GFjatLyExki82dnAFdkwBNwBvKgzEVUljtCl6ipT6NcBKyNiRfFC5+nA5jH73AW8CSAijgCOB27vZFBJ0uSmvAVdZo5GxLnA1UAfcFlmbo+Ic4rtG4FPAV+MiJtoTNGcl5n3z2BudYkjdKm6St1TNDO3AFvGrNvY9HgX8NbORpMktcMrRdUWXxSVqstCV1uccpGqy0JXW+xzqbosdLXFS/+l6rLQ1RbrXKouC11tcYAuVZeFrrY45SJVl4UuSTVhoUtSTVjoklQTFrok1YSFLkk1YaFLUk1Y6JJUE6XePlfaeOaJ/OSOB7sdQ9IkLHSV8soVh7HmJUd1O4akSTjlolK8QFSqPgtdkmrCQpekmrDQVYq3npOqz0KXpJqw0CWpJix0leOMi1R5Frok1YSFLkk1YaGrFC8skqrPQpekmrDQJakmLHRJqgkLXaU4hS5VX6lCj4g1EbEjIoYiYsME+6yOiJ9FxPaIuKazMSVJU5ny/dAjog+4GHgLMAxcFxGbM/Pmpn0WAp8H1mTmXRFx+EwFliS1VmaEfjIwlJm3Z+Ye4HJg3Zh93g1ckZl3AWTmfZ2NqW4Lz1uUKq9MoS8GdjYtDxfrmh0HHBoR34+I6yPirFZfKCLWR8TWiNg6MjIyvcSSpJbKFHqroVmOWe4HTgLeBpwKfDIijht3UOamzBzMzMGBgYG2w0qSJlbmnqLDwNKm5SXArhb73J+ZjwKPRsQPgJcDt3YkpbrOCRep+sqM0K8DVkbEiog4ADgd2Dxmn28Cr4uI/og4CHglcEtno0qSJjPlCD0zRyPiXOBqoA+4LDO3R8Q5xfaNmXlLRHwbuBHYC1yamdtmMrgk6bnKTLmQmVuALWPWbRyz/BngM52LpirxJBep+rxSVJJqwkKXpJqw0CWpJix0lRKeuChVnoUuSTVhoUtSTVjoKsXTFqXqs9AlqSYsdEmqCQtdkmrCQpekmrDQJakmLHSNs/r48Tcf8SwXqfosdEmqCQtd4zgYl3qTha5SfC8XqfosdEmqCQtdkmrCQpekmrDQVYqnLUrVZ6FLUk1Y6JJUExa6SnHGRao+C12SasJCl6SasNA1TrQ4paXVOknVYqFLUk1Y6JJUExa6SnHCRao+C12SasJCl6SaKFXoEbEmInZExFBEbJhkv9+LiKcj4g87F1FV4EkuUvVNWegR0QdcDKwFVgFnRMSqCfa7ELi60yG1f2VmtyNImoYyI/STgaHMvD0z9wCXA+ta7PcR4BvAfR3Mpy7wnHOpN5Up9MXAzqbl4WLdsyJiMfAHwMbJvlBErI+IrRGxdWRkpN2skqRJlCn0VsO1sb+TfxY4LzOfnuwLZeamzBzMzMGBgYGyGVUBjtql6usvsc8wsLRpeQmwa8w+g8DlxZN+EXBaRIxm5pUdSSlJmlKZQr8OWBkRK4C7gdOBdzfvkJkrnnkcEV8ErrLMJWn/mrLQM3M0Is6lcfZKH3BZZm6PiHOK7ZPOm6v3OLki9aYyI3QycwuwZcy6lkWeme/f91iSpHZ5pagk1YSFLkk1YaFLUk1Y6JJUExa6JNWEhS5JNWGhS1JNWOiSVBMWuiTVhIWucXxjRak3WeiSVBMWusbxDnRSb7LQNY5TLlJvstAlqSYsdEmqCQtdkmrCQlcLTqJLvchCVwue5iL1IgtdkmrCQpekmrDQJakmLHRJqgkLXeN46b/Umyx0TWjeXP95SL3EZ6xa+qt3rOKqj7y22zEktaG/2wFUTe9/zYpuR5DUJkfoGscpdKk3WeiSVBMWuiTVhIUuSTVRqtAjYk1E7IiIoYjY0GL7eyLixuLjxxHx8s5H1f6Snogu9aQpCz0i+oCLgbXAKuCMiFg1Zrc7gDdk5suATwGbOh1UkjS5MiP0k4GhzLw9M/cAlwPrmnfIzB9n5q+LxWuBJZ2NKUmaSplCXwzsbFoeLtZN5APAt1ptiIj1EbE1IraOjIyUT6n9ygkXqTeVKfRWt69p+ZyPiDfSKPTzWm3PzE2ZOZiZgwMDA+VTSpKmVOZK0WFgadPyEmDX2J0i4mXApcDazHygM/EkSWWVGaFfB6yMiBURcQBwOrC5eYeIWAZcAbw3M2/tfExJ0lSmHKFn5mhEnAtcDfQBl2Xm9og4p9i+EbgAOAz4fEQAjGbm4MzF1kzyrEWpN5V6c67M3AJsGbNuY9PjDwIf7Gw0SVI7vFJUkmrCQpekmrDQNY5T6FJvstAlqSYsdEmqCQtdkmrCQtc4vn2u1JssdEmqCQtdkmrCQpekmrDQJakmLHRJqgkLvYa23f0wyzf8B9ff+eupd5ZUGxZ6DV1za+P2fv91y73TOt6zFqXeZKFLUk1Y6JJUExa6JNVEqTsWqR52PvhYqf3SN9CVepKFPou87tPf63YESTPIKRdJqgkLXeN42qLUmyx0SaoJC32W2LvXYbdUdxb6LPG08yhS7Vnos8TTbYzQ7X6pN1nos0Q7hS6pN1nos8SohS7VnoVeY488Mcquhx4HfFFUmg0s9Br78rV38uq//S7Q3gjdS/+l3mShzxJ7faVTqj0LfRb45JXbnEOXZoFShR4RayJiR0QMRcSGFtsjIj5XbL8xIk7sfFRN15evvZMLv/XzbseQNMOmfLfFiOgDLgbeAgwD10XE5sy8uWm3tcDK4uOVwCXFZ1XE5ht2ld73kSdHn3187ht/h745MRORJHVYmbfPPRkYyszbASLicmAd0Fzo64AvZWYC10bEwog4KjPv6XTga24d4W+uunnqHWex2+57pK39P7T6WC75/i+eXT58wbxnH3/s1OM7lkvSzCpT6IuBnU3Lw4wffbfaZzHwnEKPiPXAeoBly5a1mxWA+Qf2s/KI+dM6drY4dmA+397+K05ctpCf3vUQCw7sZ/eToxzQP4cjD5lH/5xg+NeP864Tjuali5/Pe1+1nJOWHco1t46w9iVHsuroQ7r9I0iahjKF3ur37bGvsJXZh8zcBGwCGBwcnNardCe98FBOeuFJ0zlUk3jzqiN486ojuh1D0j4o86LoMLC0aXkJMHZCtsw+kqQZVKbQrwNWRsSKiDgAOB3YPGafzcBZxdkupwAPz8T8uSRpYlNOuWTmaEScC1wN9AGXZeb2iDin2L4R2AKcBgwBjwFnz1xkSVIrpW4SnZlbaJR287qNTY8T+HBno0mS2uGVopJUExa6JNWEhS5JNWGhS1JNRHbpbVUjYgS4c5qHLwLu72CcmWDGfVf1fFD9jFXPB2Zs1wszc6DVhq4V+r6IiK2ZOdjtHJMx476rej6ofsaq5wMzdpJTLpJUExa6JNVErxb6pm4HKMGM+67q+aD6GaueD8zYMT05hy5JGq9XR+iSpDEsdEmqiZ4r9KluWL2fMiyNiO9FxC0RsT0iPlqsf0FE/GdE3FZ8PrTpmE8UmXdExKn7MWtfRPxfRFxVtYzFrQq/HhE/L/4sX1WlfMX3/LPi73hbRHwtIuZ1O2NEXBYR90XEtqZ1bWeKiJMi4qZi2+cioiM3j50g32eKv+cbI+LfImJht/JNlLFp28ciIiNiUTczTktm9swHjbfv/QVwDHAAcAOwqgs5jgJOLB4vAG4FVgGfBjYU6zcAFxaPVxVZDwRWFD9D337K+ufAvwBXFcuVyQj8M/DB4vEBwMKK5VsM3AE8r1j+V+D93c4IvB44EdjWtK7tTMD/Aq+iccexbwFrZzDfW4H+4vGF3cw3UcZi/VIabxV+J7Comxmn89FrI/Rnb1idmXuAZ25YvV9l5j2Z+dPi8W7gFhpP/nU0Sori87uKx+uAyzPzycy8g8b7xp880zkjYgnwNuDSptWVyBgRh9B4Un0BIDP3ZOZDVcnXpB94XkT0AwfRuBNXVzNm5g+AB8esbitTRBwFHJKZ/5ONZvpS0zEdz5eZ38nM0WLxWhp3NetKvokyFv4R+DjPvYVmVzJOR68V+kQ3o+6aiFgOnAD8BDgiizs1FZ8PL3brVu7P0vjHubdpXVUyHgOMAP9UTAldGhEHVygfmXk38HfAXTRueP5wZn6nShmbtJtpcfF47Pr94Y9pjGahQvki4p3A3Zl5w5hNlck4lV4r9FI3o95fImI+8A3gTzPzN5Pt2mLdjOaOiLcD92Xm9WUPabFuJjP20/iV95LMPAF4lMZUwUS68Wd4KI3R2QrgaODgiDhzskNarOv2ecETZepK1og4HxgFvvrMqgly7Nd8EXEQcD5wQavNE2Sp3N93rxV6ZW5GHRFzaZT5VzPzimL1vcWvYRSf7yvWdyP3a4B3RsQvaUxN/X5EfKVCGYeB4cz8SbH8dRoFX5V8AG8G7sjMkcx8CrgCeHXFMj6j3UzD/Hbao3n9jImI9wFvB95TTFFUKd+xNP7jvqF4ziwBfhoRR1Yo45R6rdDL3LB6xhWvZH8BuCUz/6Fp02bgfcXj9wHfbFp/ekQcGBErgJU0XkyZMZn5icxckpnLafw5fTczz6xKxsz8FbAzIo4vVr0JuLkq+Qp3AadExEHF3/mbaLxeUqWMz2grUzEtszsiTil+trOajum4iFgDnAe8MzMfG5O76/ky86bMPDwzlxfPmWEaJz78qioZS+nmK7LT+aBxM+pbabzSfH6XMryWxq9WNwI/Kz5OAw4D/hu4rfj8gqZjzi8y72A/vxIOrOa3Z7lUJiPwCmBr8ed4JXBolfIV3/OvgZ8D24Av0zjToasZga/RmNN/ikbxfGA6mYDB4uf6BXARxZXjM5RviMY89DPPl43dyjdRxjHbf0lxlku3Mk7nw0v/Jakmem3KRZI0AQtdkmrCQpekmrDQJakmLHRJqgkLXZJqwkKXpJr4f1KDu6GG1MvFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(proba_ests[:,3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
